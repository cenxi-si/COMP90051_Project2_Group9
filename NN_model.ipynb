{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d78a3c",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d5bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e763c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numbers that will used\n",
    "max_prolific = 99\n",
    "n_text = 4999\n",
    "n_authors = 21245\n",
    "n_prolific = 100\n",
    "n_years = 19\n",
    "n_venues = 464\n",
    "batch_size = 40\n",
    "hidden_dim = 200\n",
    "output_dim = 101\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1d749",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496b4113",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  data processing methods\n",
    "\n",
    "# get prolific authors(0-99) from the author list\n",
    "def retain_prolific(author_list: list):\n",
    "    return [x for x in author_list if x < 100]\n",
    "\n",
    "# get coauthors(>99) from the author list\n",
    "def get_coauthor(author_list: list):\n",
    "    return [x for x in author_list if x >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train json file\n",
    "train_filename = 'train.json'\n",
    "with open(train_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "test_filename = 'test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# get a copy\n",
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "# extract prolific authors and coauthors\n",
    "data_df = pd.DataFrame.from_dict(train)\n",
    "data_df['prolific'] = data_df.apply(lambda x: retain_prolific(x['authors']), axis=1)\n",
    "data_df['coauthors'] = data_df.apply(lambda x: get_coauthor(x['authors']), axis=1)\n",
    "data_df = data_df.drop(['authors'],axis=1)\n",
    "test_df = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5930a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17409\n",
      "7094\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df = train_test_split(data_df, test_size=0.05,random_state=42)\n",
    "length = train_df['prolific'].str.len()\n",
    "\n",
    "# number of papers without any prolific author\n",
    "count_empty = (length == 0).sum()\n",
    "\n",
    "# number of papers with prolific authors\n",
    "count_non_emtpy = (length >0).sum()\n",
    "print(count_empty)\n",
    "print(count_non_emtpy)\n",
    "train_without = train_df[train_df['prolific'].str.len() == 0]\n",
    "train_with = train_df[train_df['prolific'].str.len() > 0]\n",
    "\n",
    "# sample same amount of data and concat\n",
    "train_df = pd.concat([train_with, train_without.sample(len(train_with))])\n",
    "\n",
    "# reset index from 0\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "validation_df = validation_df.iloc[10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f1b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "validating_prolifics = validation_df['prolific']\n",
    "for element in validating_prolifics:\n",
    "   if len(element) == 0:\n",
    "    element.append(-1)\n",
    "validation_df = validation_df.drop(['prolific'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be123cd2",
   "metadata": {},
   "source": [
    "### One-Hot Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fd2487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_torch(df, have_prolific):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # abstract and title\n",
    "        abstract_list = [0] * n_text\n",
    "        title_list = [0] * n_text\n",
    "        current_row = df.loc[i]\n",
    "        # count word frequency in title and abstract\n",
    "        abstract_freq = collections.Counter(current_row['abstract'])\n",
    "        title_freq = collections.Counter(current_row['title'])\n",
    "        for key, value in dict(abstract_freq).items():\n",
    "            abstract_list[key-1] = value\n",
    "        for key, value in dict(title_freq).items():\n",
    "            title_list[key-1] = value\n",
    "        # year\n",
    "        year_list = [0] * n_years\n",
    "        year_list[current_row['year']-1] = 1\n",
    "        # venue\n",
    "        venue_list = [0] * (n_venues + 2) # 466 elements with the last element for empty venue\n",
    "        if current_row['venue'] == '':\n",
    "            venue_list[-1] = 1\n",
    "        else:\n",
    "            venue_list[current_row['venue']] = 1\n",
    "        # coauthors\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if current_row['coauthors'] == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in current_row['coauthors']:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "           \n",
    "        combined_features = coauthor_list\n",
    "        features.append(np.array(combined_features))\n",
    "        \n",
    "        if have_prolific == True:\n",
    "            # prolific authors\n",
    "            prolific_list = [0] * (n_prolific + 1) # 101 elements with the last element for empty coauthors\n",
    "            if current_row['prolific'] == []:\n",
    "                prolific_list[-1] = 1\n",
    "            else:\n",
    "                for prolific in current_row['prolific']:\n",
    "                    prolific_list[prolific] = 1\n",
    "            targets.append(np.array(prolific_list))\n",
    "    if have_prolific == True:\n",
    "        X_train = np.vstack(features)\n",
    "        y_train = np.array(targets)\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        X_test = np.vstack(features)\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6177e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, istrain):\n",
    "        self.X = X\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.istrain == True:\n",
    "            return self.X[index], self.y[index]\n",
    "        else:\n",
    "            return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af45b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = combine_features_torch(train_df, have_prolific=True)\n",
    "X_validation = combine_features_torch(validation_df, have_prolific=False)\n",
    "X_test = combine_features_torch(test_df, have_prolific=False)\n",
    "training_df = AuthorDataset(X_train, y_train, istrain = True)\n",
    "validating_df = AuthorDataset(X_validation, y_train, istrain=False)\n",
    "testing_df = AuthorDataset(X_test, y_train, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39d3fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collate function\n",
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"x\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            output['x'] += [x]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"x\": []}\n",
    "        for data in batch:\n",
    "            output['x'] += [data]\n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96490e65",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "793f91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zihan\\AppData\\Local\\Temp\\ipykernel_21532\\437068522.py:22: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  output['x'] = torch.tensor(output['x'], dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "validation_dataloader = DataLoader(dataset = validating_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(test_dataloader))\n",
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "295908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultilabelModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.Sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear2 = torch.nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.linear1(x)\n",
    "        output = self.linear2(output)\n",
    "        output = self.Sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72ff4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5174, 0.5193, 0.4917,  ..., 0.5064, 0.4899, 0.4857],\n",
      "        [0.5152, 0.5195, 0.4895,  ..., 0.5066, 0.4904, 0.4873],\n",
      "        [0.5166, 0.5191, 0.4859,  ..., 0.5073, 0.4917, 0.4854],\n",
      "        ...,\n",
      "        [0.5147, 0.5185, 0.4886,  ..., 0.5070, 0.4905, 0.4868],\n",
      "        [0.5170, 0.5195, 0.4890,  ..., 0.5065, 0.4885, 0.4851],\n",
      "        [0.5157, 0.5190, 0.4888,  ..., 0.5066, 0.4909, 0.4871]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "clf = MultilabelModel(21147, output_dim)\n",
    "print(clf(dataiter['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03e05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, 101)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x.reshape([x.shape[0],1,x.shape[1]])\n",
    "        h0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim, device=out.device)\n",
    "        c0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim, device=out.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, (hn, cn) = self.lstm(out, (h0, c0))  \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5ec8ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4940, 0.5066, 0.5206,  ..., 0.5018, 0.4944, 0.5181],\n",
      "        [0.4908, 0.5010, 0.5140,  ..., 0.4994, 0.4991, 0.5259],\n",
      "        [0.4949, 0.5022, 0.5114,  ..., 0.5062, 0.4960, 0.5180],\n",
      "        ...,\n",
      "        [0.4982, 0.5026, 0.5132,  ..., 0.4971, 0.5015, 0.5190],\n",
      "        [0.4954, 0.5106, 0.5176,  ..., 0.4992, 0.4975, 0.5236],\n",
      "        [0.4987, 0.4915, 0.5164,  ..., 0.5033, 0.4988, 0.5225]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "clf = LSTM(21147, 64, 128, 1)\n",
    "print(clf(dataiter['x']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8e200",
   "metadata": {},
   "source": [
    "### GPU Mode if Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2df2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "# Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684c9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_mode=torch.cuda.is_available()\n",
    "if gpu_mode:\n",
    "    clf.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6594ba",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f2b43a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100, loss = 0.0439, training f1 score = 0.0000\n",
      "epoch 2 / 100, loss = 0.0370, training f1 score = 0.5000\n",
      "epoch 3 / 100, loss = 0.0535, training f1 score = 0.4286\n",
      "epoch 4 / 100, loss = 0.0451, training f1 score = 0.4286\n",
      "epoch 5 / 100, loss = 0.0365, training f1 score = 0.4643\n",
      "epoch 6 / 100, loss = 0.0343, training f1 score = 0.3929\n",
      "epoch 7 / 100, loss = 0.0342, training f1 score = 0.3929\n",
      "epoch 8 / 100, loss = 0.0247, training f1 score = 0.5714\n",
      "epoch 9 / 100, loss = 0.0181, training f1 score = 0.6429\n",
      "epoch 10 / 100, loss = 0.0234, training f1 score = 0.5738\n",
      "epoch 11 / 100, loss = 0.0130, training f1 score = 0.7024\n",
      "epoch 12 / 100, loss = 0.0099, training f1 score = 0.6429\n",
      "epoch 13 / 100, loss = 0.0094, training f1 score = 0.6786\n",
      "epoch 14 / 100, loss = 0.0088, training f1 score = 0.7381\n",
      "epoch 15 / 100, loss = 0.0112, training f1 score = 0.8214\n",
      "epoch 16 / 100, loss = 0.0087, training f1 score = 0.7810\n",
      "epoch 17 / 100, loss = 0.0048, training f1 score = 0.8929\n",
      "epoch 18 / 100, loss = 0.0071, training f1 score = 0.8571\n",
      "epoch 19 / 100, loss = 0.0086, training f1 score = 0.8214\n",
      "epoch 20 / 100, loss = 0.0052, training f1 score = 0.8690\n",
      "epoch 21 / 100, loss = 0.0026, training f1 score = 0.9464\n",
      "epoch 22 / 100, loss = 0.0062, training f1 score = 0.8333\n",
      "epoch 23 / 100, loss = 0.0059, training f1 score = 0.9048\n",
      "epoch 24 / 100, loss = 0.0065, training f1 score = 0.8095\n",
      "epoch 25 / 100, loss = 0.0015, training f1 score = 0.9643\n",
      "epoch 26 / 100, loss = 0.0031, training f1 score = 0.8810\n",
      "epoch 27 / 100, loss = 0.0027, training f1 score = 0.9405\n",
      "epoch 28 / 100, loss = 0.0007, training f1 score = 1.0000\n",
      "epoch 29 / 100, loss = 0.0022, training f1 score = 0.9524\n",
      "epoch 30 / 100, loss = 0.0027, training f1 score = 0.9524\n",
      "epoch 31 / 100, loss = 0.0102, training f1 score = 0.8929\n",
      "epoch 32 / 100, loss = 0.0036, training f1 score = 0.9167\n",
      "epoch 33 / 100, loss = 0.0076, training f1 score = 0.9167\n",
      "epoch 34 / 100, loss = 0.0012, training f1 score = 0.9643\n",
      "epoch 35 / 100, loss = 0.0031, training f1 score = 0.9286\n",
      "epoch 36 / 100, loss = 0.0060, training f1 score = 0.8988\n",
      "epoch 37 / 100, loss = 0.0018, training f1 score = 0.9643\n",
      "epoch 38 / 100, loss = 0.0007, training f1 score = 1.0000\n",
      "epoch 39 / 100, loss = 0.0035, training f1 score = 0.9405\n",
      "epoch 40 / 100, loss = 0.0007, training f1 score = 1.0000\n",
      "epoch 41 / 100, loss = 0.0025, training f1 score = 0.9643\n",
      "epoch 42 / 100, loss = 0.0104, training f1 score = 0.7976\n",
      "epoch 43 / 100, loss = 0.0038, training f1 score = 0.9643\n",
      "epoch 44 / 100, loss = 0.0115, training f1 score = 0.8571\n",
      "epoch 45 / 100, loss = 0.0081, training f1 score = 0.9048\n",
      "epoch 46 / 100, loss = 0.0107, training f1 score = 0.8333\n",
      "epoch 47 / 100, loss = 0.0058, training f1 score = 0.8810\n",
      "epoch 48 / 100, loss = 0.0052, training f1 score = 0.8810\n",
      "epoch 49 / 100, loss = 0.0028, training f1 score = 0.9286\n",
      "epoch 50 / 100, loss = 0.0010, training f1 score = 1.0000\n",
      "epoch 51 / 100, loss = 0.0017, training f1 score = 0.9405\n",
      "epoch 52 / 100, loss = 0.0004, training f1 score = 1.0000\n",
      "epoch 53 / 100, loss = 0.0025, training f1 score = 0.9464\n",
      "epoch 54 / 100, loss = 0.0073, training f1 score = 0.8810\n",
      "epoch 55 / 100, loss = 0.0005, training f1 score = 1.0000\n",
      "epoch 56 / 100, loss = 0.0025, training f1 score = 0.9286\n",
      "epoch 57 / 100, loss = 0.0008, training f1 score = 0.9643\n",
      "epoch 58 / 100, loss = 0.0065, training f1 score = 0.8571\n",
      "epoch 59 / 100, loss = 0.0034, training f1 score = 0.9167\n",
      "epoch 60 / 100, loss = 0.0015, training f1 score = 0.9821\n",
      "epoch 61 / 100, loss = 0.0022, training f1 score = 0.9405\n",
      "epoch 62 / 100, loss = 0.0012, training f1 score = 0.9881\n",
      "epoch 63 / 100, loss = 0.0025, training f1 score = 0.9286\n",
      "epoch 64 / 100, loss = 0.0025, training f1 score = 0.9167\n",
      "epoch 65 / 100, loss = 0.0022, training f1 score = 0.9286\n",
      "epoch 66 / 100, loss = 0.0018, training f1 score = 0.9524\n",
      "epoch 67 / 100, loss = 0.0071, training f1 score = 0.8929\n",
      "epoch 68 / 100, loss = 0.0053, training f1 score = 0.9167\n",
      "epoch 69 / 100, loss = 0.0019, training f1 score = 0.9286\n",
      "epoch 70 / 100, loss = 0.0054, training f1 score = 0.9286\n",
      "epoch 71 / 100, loss = 0.0028, training f1 score = 0.9405\n",
      "epoch 72 / 100, loss = 0.0003, training f1 score = 1.0000\n",
      "epoch 73 / 100, loss = 0.0060, training f1 score = 0.9524\n",
      "epoch 74 / 100, loss = 0.0030, training f1 score = 0.9524\n",
      "epoch 75 / 100, loss = 0.0021, training f1 score = 0.9345\n",
      "epoch 76 / 100, loss = 0.0021, training f1 score = 0.9286\n",
      "epoch 77 / 100, loss = 0.0045, training f1 score = 0.9167\n",
      "epoch 78 / 100, loss = 0.0017, training f1 score = 0.9286\n",
      "epoch 79 / 100, loss = 0.0019, training f1 score = 0.9571\n",
      "epoch 80 / 100, loss = 0.0050, training f1 score = 0.9452\n",
      "epoch 81 / 100, loss = 0.0016, training f1 score = 0.9464\n",
      "epoch 82 / 100, loss = 0.0030, training f1 score = 0.9643\n",
      "epoch 83 / 100, loss = 0.0050, training f1 score = 0.9405\n",
      "epoch 84 / 100, loss = 0.0031, training f1 score = 0.9167\n",
      "epoch 85 / 100, loss = 0.0020, training f1 score = 0.9286\n",
      "epoch 86 / 100, loss = 0.0011, training f1 score = 0.9643\n",
      "epoch 87 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 88 / 100, loss = 0.0023, training f1 score = 0.9643\n",
      "epoch 89 / 100, loss = 0.0070, training f1 score = 0.8571\n",
      "epoch 90 / 100, loss = 0.0051, training f1 score = 0.9286\n",
      "epoch 91 / 100, loss = 0.0020, training f1 score = 0.9524\n",
      "epoch 92 / 100, loss = 0.0073, training f1 score = 0.9286\n",
      "epoch 93 / 100, loss = 0.0016, training f1 score = 0.9643\n",
      "epoch 94 / 100, loss = 0.0053, training f1 score = 0.9286\n",
      "epoch 95 / 100, loss = 0.0045, training f1 score = 0.9524\n",
      "epoch 96 / 100, loss = 0.0053, training f1 score = 0.9286\n",
      "epoch 97 / 100, loss = 0.0037, training f1 score = 0.9167\n",
      "epoch 98 / 100, loss = 0.0038, training f1 score = 0.8929\n",
      "epoch 99 / 100, loss = 0.0073, training f1 score = 0.8214\n",
      "epoch 100 / 100, loss = 0.0014, training f1 score = 0.9524\n"
     ]
    }
   ],
   "source": [
    "# loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(),lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        # if using GPU...\n",
    "        if gpu_mode == True:\n",
    "            gpu_batch = {}\n",
    "            gpu_batch['x']=batch['x'].cuda()\n",
    "            gpu_batch['target']=batch['target'].cuda()\n",
    "            batch = gpu_batch\n",
    "\n",
    "        # forward\n",
    "        outputs = clf(batch['x'])\n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().cpu().numpy()>=0.5, 1, 0)\n",
    "        f1_acc = f1_score(batch['target'].detach().cpu().numpy(), predictions, average=\"samples\", zero_division=1)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if (i + 1) % 100 == 0:\n",
    "    print(f'epoch {epoch + 1} / {num_epochs}, loss = {loss.item():.4f}, training f1 score = {f1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075cc35",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acbd061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "def generate_preds(dataloader):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for index, batch in enumerate(dataloader):\n",
    "            if gpu_mode == True:\n",
    "                gpu_batch = {}\n",
    "                gpu_batch['x']=batch['x'].cuda()\n",
    "                batch = gpu_batch\n",
    "            outputs = clf(batch['x'])\n",
    "\n",
    "            predictions = np.where(outputs.detach().cpu().numpy()>=0.5, 1, 0)\n",
    "            preds.append(predictions)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5ef15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_preds = generate_preds(validation_dataloader)\n",
    "test_preds = generate_preds(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd2c9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe of output\n",
    "def prediction_df(predictions:list, isString: bool):\n",
    "    identifiers = np.shape(predictions)[0]*np.shape(predictions)[1]\n",
    "    NN_output = pd.DataFrame([*range(0,identifiers)], columns=['ID']) # column of ID\n",
    "    #NN_output['Predict'] = ''  # column of predict      \n",
    "    final_results = []\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        for j in range(batch_size):\n",
    "            final_results.append(predictions[i][j])\n",
    "    predict = []\n",
    "    for i in range(len(final_results)):\n",
    "        \n",
    "        result = final_results[i]\n",
    "        if isString == True:\n",
    "            if result[-1] == 1 or len(np.where(result == 1)[0]) == 0:  \n",
    "                predict.append(-1)\n",
    "            else:\n",
    "                predict.append(' '.join(str(e) for e in np.where(result==1)[0]))\n",
    "        else:\n",
    "            if result[-1] == 1 or len(np.where(result == 1)[0]) == 0:  \n",
    "                predict.append([-1])\n",
    "                \n",
    "            else:\n",
    "                predict.append(list(np.where(result==1)[0]))\n",
    "    NN_output['Predict'] = predict\n",
    "    return NN_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dee85b",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d4f1f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50546875"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation accuracy\n",
    "validation_prediction = prediction_df(validation_preds, isString=False)['Predict']\n",
    "comparison = (validation_prediction == validating_prolifics)\n",
    "comparison.sum()/len(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef402846",
   "metadata": {},
   "source": [
    "### Output Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "711026e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Predict\n",
       "0      0      92\n",
       "1      1      -1\n",
       "2      2      31\n",
       "3      3      -1\n",
       "4      4      -1\n",
       "..   ...     ...\n",
       "795  795      54\n",
       "796  796      97\n",
       "797  797      13\n",
       "798  798      71\n",
       "799  799      -1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_test_output = prediction_df(test_preds,isString=True)\n",
    "NN_test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecf63636",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_test_output.to_csv('./NN_split_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
