{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1c1e0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from time import time\n",
    "%matplotlib inline\n",
    "\n",
    "# Tools for processing data\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, classification_report, confusion_matrix, make_scorer, f1_score\n",
    "# Classifiers, supervised and unsupervised\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b08156",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prolific = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83876ca",
   "metadata": {},
   "source": [
    "# Data Prepossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5f0d941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train json file\n",
    "train_filename = './data/train.json'\n",
    "with open(train_filename, 'r', encoding='utf-8') as f:\n",
    "    train = json.load(f)\n",
    "\n",
    "# extract coauthors as a new key from train.json\n",
    "for i in range(len(train)):\n",
    "    coauthors = []\n",
    "    prolific_authors = []\n",
    "    train[i]['text'] = train[i]['abstract']\n",
    "    for auth in train[i]['authors']:\n",
    "        if auth >= max_prolific:\n",
    "            coauthors.append(auth)\n",
    "        else:\n",
    "            prolific_authors.append(auth)\n",
    "    train[i]['coauthors'] = coauthors\n",
    "    if len(prolific_authors) == 0:\n",
    "        prolific_authors.append(-1)\n",
    "    train[i]['prolific_authors'] = prolific_authors\n",
    "    train[i]['text'].extend(train[i]['title'])\n",
    "    \n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "\n",
    "# First ten authors with more than X articles\n",
    "names = train_df.prolific_authors.value_counts()[train_df.prolific_authors.value_counts()>100][-10:].index.tolist()\n",
    "names_list = []\n",
    "for sublist in names:\n",
    "    for item in sublist:\n",
    "        names_list.append(item)\n",
    "# choose all the articles written by the first 10 authors         \n",
    "chosen_authors = []\n",
    "chosen_article = []\n",
    "for index, row in train_df.iterrows():\n",
    "    curr_au = row['prolific_authors']\n",
    "    curr_text = row['text']\n",
    "    if any(item in curr_au for item in names_list):\n",
    "        chosen_authors.append(curr_au)\n",
    "        chosen_article.append(curr_text)\n",
    "\n",
    "combine = list(zip(chosen_authors, chosen_article))\n",
    "authors_data = pd.DataFrame(combine, columns=['prolific_authors', 'text'])\n",
    "authors_data = authors_data.reset_index().drop('index', 1)\n",
    "\n",
    "# extract the most-common 1000 words from each author's corpus, store them in a list, and then eliminate duplicates.\n",
    "common_words = []\n",
    "authors_docs = {}\n",
    "bow_au = []\n",
    "bow_text = []\n",
    "for name in names_list:\n",
    "    content = []\n",
    "    count = 0\n",
    "    for index, row in authors_data.iterrows():\n",
    "        if name in authors_data['prolific_authors'][index]:\n",
    "            content.extend(authors_data['text'][index])\n",
    "            if count < 50:\n",
    "                bow_text.append(authors_data['text'][index])\n",
    "                bow_au.append(name)\n",
    "                count += 1\n",
    "    authors_docs[name] = content\n",
    "    # Return the most common words of that author's corpus.\n",
    "    bow = [item[0] for item in Counter(content).most_common(1000)]\n",
    "    common_words.extend(bow)\n",
    "    \n",
    "common_words = set(common_words)\n",
    "\n",
    "combine2 = list(zip(bow_au, bow_text))\n",
    "bow_counts = pd.DataFrame(combine2, columns=['prolific_authors','text'])\n",
    "bow_counts = bow_counts.reset_index().drop('index',1)\n",
    "# Use common_words as the columns of a temporary DataFrame\n",
    "df = pd.DataFrame(columns=common_words)\n",
    "\n",
    "# Join BOW features with the author's content\n",
    "bow_counts = bow_counts.join(df)\n",
    "bow_counts.loc[:,common_words] = 0\n",
    "\n",
    "# Fill the DataFrame with counts of each feature in each article\n",
    "for i, t in enumerate(bow_counts.text):\n",
    "    for word in t:\n",
    "        if word in common_words:\n",
    "            bow_counts.loc[i,word] += 1\n",
    "y = bow_counts['prolific_authors']\n",
    "X = bow_counts.drop(['text', 'prolific_authors'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "00b16a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test json file\n",
    "test_filename = './data/test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    test = json.load(f)\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    test[i]['text'] = test[i]['abstract']\n",
    "    test[i]['text'].extend(test[i]['title'])\n",
    "test_df = pd.DataFrame.from_dict(test)\n",
    "bow_counts_test = pd.DataFrame(test_df, columns=['text'])\n",
    "bow_counts_test = bow_counts_test.reset_index().drop('index',1)\n",
    "# Join BOW features with the author's content\n",
    "bow_counts_test = bow_counts_test.join(df)\n",
    "bow_counts_test.loc[:,common_words] = 0\n",
    "# Fill the DataFrame with counts of each feature in each article\n",
    "for i, t in enumerate(bow_counts_test.text):\n",
    "    for word in t:\n",
    "        if word in common_words:\n",
    "            bow_counts_test.loc[i,word] += 1\n",
    "X_test = bow_counts_test.drop(['text'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3330940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.24, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "fa862101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'logisticregression__C': 1, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n",
      "\n",
      "Train Accuracy Score: 0.9842105263157894\n",
      "\n",
      "Test Accuracy Score: 0.5083333333333333\n",
      "\n",
      "F1-score': 0.492\n"
     ]
    }
   ],
   "source": [
    "# Parameters to optimize\n",
    "params = [{\n",
    "    'logisticregression__solver': ['newton-cg'],\n",
    "    'logisticregression__C': [0.3, 0.5, 0.7, 1],\n",
    "    'logisticregression__penalty': ['l2']\n",
    "    },{\n",
    "    'logisticregression__solver': ['saga'],\n",
    "    'logisticregression__C': [0.3, 0.5, 0.7, 1],\n",
    "    'logisticregression__penalty': ['l1','l2']\n",
    "}]\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "# Find best parameters based on scoring of choice\n",
    "gridsearch = GridSearchCV(estimator=pipe, param_grid=params, n_jobs=-1, scoring='f1_micro', cv=5).fit(X,y)\n",
    "\n",
    "# Extract best estimator\n",
    "best = gridsearch.best_estimator_\n",
    "print(\"Best parameters:\",gridsearch.best_params_)\n",
    "\n",
    "# Get train accuracy\n",
    "best = best.fit(X_train, y_train)\n",
    "train = best.score(X=X_train, y=y_train)\n",
    "print(\"\\nTrain Accuracy Score:\",train)\n",
    "\n",
    "# Get test accuracy\n",
    "test = best.score(X=X_val,y=y_val)\n",
    "print(\"\\nTest Accuracy Score:\",test)\n",
    "\n",
    "y_pred = best.predict(X_val)\n",
    "f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "print(\"\\nF1-score': %.3f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "eca5ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y_pred = best.predict(X_test)\n",
    "test_filename = './data/test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    test = json.load(f)\n",
    "    \n",
    "for i in range(len(test)):\n",
    "    test[i]['text'] = test[i]['abstract']\n",
    "    test[i]['text'].extend(test[i]['title'])\n",
    "test_df = pd.DataFrame.from_dict(test)\n",
    "\n",
    "test_df['Predict'] = final_y_pred\n",
    "result = test_df[['identifier', 'Predict']]\n",
    "result = result.rename(columns={'identifier':'ID'})\n",
    "result.to_csv('./results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8e705fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Predict\n",
       "0      0       41\n",
       "1      1       84\n",
       "2      2       53\n",
       "3      3       10\n",
       "4      4       41\n",
       "..   ...      ...\n",
       "795  795       32\n",
       "796  796       27\n",
       "797  797       10\n",
       "798  798       41\n",
       "799  799       84\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7b754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
