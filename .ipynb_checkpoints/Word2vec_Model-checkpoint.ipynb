{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "86e90b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "a41e5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prolific = 99\n",
    "n_text = 4999\n",
    "n_authors = 21245\n",
    "n_prolific = 100\n",
    "n_coauthors = n_authors - n_prolific + 1\n",
    "n_years = 19\n",
    "n_venues = 466\n",
    "#embedding_dim = 50\n",
    "batch_size = 30\n",
    "#hidden_dim = 200\n",
    "#output_dim = 100\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1dcc8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "835927d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25793, 6)"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = './data/train.json'\n",
    "test_data_path = './data/test.json'\n",
    "# read train json file\n",
    "with open(train_data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "with open(test_data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# extract coauthors as a new key from train.json\n",
    "title_list = []\n",
    "abstract_list = []\n",
    "word_list = []\n",
    "for i in range(len(raw_train)):\n",
    "    coauthors = []\n",
    "    prolific_authors = []\n",
    "    for auth in raw_train[i]['authors']:\n",
    "        if auth >= max_prolific:\n",
    "            coauthors.append(auth)\n",
    "        else:\n",
    "            prolific_authors.append(auth)\n",
    "    if len(prolific_authors) == 0:\n",
    "        prolific_authors = -1\n",
    "    raw_train[i]['coauthors'] = coauthors\n",
    "    raw_train[i]['prolific_authors'] = prolific_authors\n",
    "    \n",
    "train_df = pd.DataFrame.from_dict(raw_train)\n",
    "train_df = train_df.drop(['authors'], axis=1)\n",
    "train_df['venue'] = train_df['venue'].replace('', 465)\n",
    "for i in range(len(train_df)):\n",
    "    title_list.append(train_df['title'][i])\n",
    "    abstract_list.append(train_df['abstract'][i])\n",
    "    word_list.append(train_df['title'][i])\n",
    "    word_list.append(train_df['abstract'][i])\n",
    "\n",
    "    \n",
    "test_df = pd.DataFrame.from_dict(raw_test)\n",
    "test_df['venue'] = test_df['venue'].replace('', 465)\n",
    "for i in range(len(test_df)):\n",
    "    title_list.append(test_df['title'][i])\n",
    "    abstract_list.append(test_df['abstract'][i])\n",
    "    word_list.append(test_df['title'][i])\n",
    "    word_list.append(test_df['abstract'][i])\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "42b3bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3522, 2223, 1653], [2085, 1719, 1846, 1745, 2243, 1553, 1606, 1596, 42, 41, 1606, 1665, 40, 1615, 1677, 40, 127, 43, 140, 50, 1583, 43], [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 56, 1687, 1644, 1546, 46, 1624, 1547, 4226], [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813, 1926, 1527, 1623, 1621, 50, 1620, 1632], [46, 1617, 1667, 3979, 2073, 37, 53, 2080, 1545, 40, 1804, 1530, 2587, 57, 4624], [34, 3646, 2073, 2035, 2346, 1886, 1543, 57, 1627, 11, 53, 1584, 1903, 3628, 1724], [1615, 1966, 11, 3495, 1656, 4345, 24, 2353, 1826, 2156, 3781, 4692], [3591, 4914, 46, 2421, 1608, 37, 1740, 1825, 1549, 57, 45, 2303, 1539, 2154, 51], [1560, 1694, 11, 1546, 11, 3066, 1728, 47, 1603, 1553, 11, 1546, 11, 1594, 1531, 1532, 1547], [1751, 44, 3474, 1854, 1872, 1538, 24, 2574, 52, 1918, 57, 1527, 46, 1528, 1727, 1525, 2149], [47, 1570, 40, 1733, 1735, 1540, 1525, 1535, 1540, 1863, 1543, 47, 1574, 1541, 1854, 1549, 2796, 1854, 53, 1540, 1537, 4454, 2062, 1538, 57, 1548, 3391], [1578, 1528, 11, 3716, 55, 47, 11, 1560, 1746, 1543, 50, 1620, 2388, 1547, 47, 1603], [37, 2375, 1568, 1910, 1772, 1543, 1534, 1588, 3632, 57], [3591, 37, 1596, 1567, 37, 1662, 1707, 1704, 1964, 1540, 2543, 1544, 1600, 1929, 1773, 1531, 4547, 1803, 1533, 1886], [47, 1574, 1541, 2812, 10, 3255, 1644, 1549, 1536, 1543, 1551, 1728, 1747, 1671, 1575, 44, 1813, 1587, 1780, 1553, 37, 55, 1529, 1589, 1629, 33, 1660, 51], [1542, 1723, 53, 1584, 2943, 1525, 47, 1945, 2014, 3207, 1545, 46, 1624, 1547, 56, 1687, 1644], [1731, 1578, 1528, 2973, 1561, 1551, 1547, 1554, 40, 4972], [46, 1910, 35, 1599, 1542, 2601, 1543, 1530, 4625, 1744, 3591, 1531, 1684], [47, 1574, 1541, 2812, 1543, 56, 3569, 1545, 1564, 1555, 1527, 47, 1603, 51, 1525, 37, 1766, 1549, 1540, 3267, 1553]]\n"
     ]
    }
   ],
   "source": [
    "print(title_list[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "758c2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "titlemodel = Word2Vec(title_list, min_count=1, vector_size=128)\n",
    "input_size = 128\n",
    "word_vectors = titlemodel.wv\n",
    "keyword_list = []\n",
    "for i in range(len(train_df)):\n",
    "    title_i = title_list[i]\n",
    "    keyword_vec = np.zeros(input_size)\n",
    "    for word in title_i:\n",
    "        keyword_vec += word_vectors[word]\n",
    "    keyword_vec = keyword_vec/len(title_i)\n",
    "    keyword_list.append(keyword_vec)\n",
    "keyword_list = np.array(keyword_list)\n",
    "\n",
    "\n",
    "\n",
    "#wordmodel = Word2Vec(word_list, min_count=1)\n",
    "#wordmodel.save(\"word_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "799d1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractmodel = Word2Vec(abstract_list, min_count=1, vector_size=128)\n",
    "input_size = 128\n",
    "word_vectors2 = abstractmodel.wv\n",
    "keyword_list2 = []\n",
    "for i in range(len(train_df)):\n",
    "    abstract_i = abstract_list[i]\n",
    "    keyword_vec = np.zeros(input_size)\n",
    "    for word in abstract_i:\n",
    "        keyword_vec += word_vectors2[word]\n",
    "    keyword_vec = keyword_vec/len(abstract_i)\n",
    "    keyword_list2.append(keyword_vec)\n",
    "keyword_list2 = np.array(keyword_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "ca7e3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48349956 -0.51170217  0.11739261 ...  0.60842679 -0.13248341\n",
      "   0.71195911]\n",
      " [-0.42123375 -0.51167642  0.72696966 ... -0.17041562  0.27131101\n",
      "   0.20101655]\n",
      " [ 0.33492874 -0.41464009  0.30027379 ...  0.27510964 -0.09162126\n",
      "   0.18025668]\n",
      " ...\n",
      " [ 0.08501742 -0.39033312  0.44491885 ... -0.27592777  0.33888846\n",
      "   0.23611297]\n",
      " [-0.60112178 -0.60781407  0.48994653 ...  0.24793403  0.22349386\n",
      "   0.41398034]\n",
      " [ 0.08621521 -0.3738243   0.1974229  ...  0.33539617  0.09805431\n",
      "   0.30733421]]\n"
     ]
    }
   ],
   "source": [
    "keywords = keyword_list + keyword_list2\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "5a437f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>prolific_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n",
       "      <td>20</td>\n",
       "      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n",
       "      <td>[13720]</td>\n",
       "      <td>[42, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n",
       "      <td>[1359, 15881]</td>\n",
       "      <td>[45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[97]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                           abstract  venue  \\\n",
       "0     9  [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...     20   \n",
       "1    15  [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...      2   \n",
       "2    10  [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...      4   \n",
       "\n",
       "                                               title      coauthors  \\\n",
       "0  [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...        [13720]   \n",
       "1  [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...  [1359, 15881]   \n",
       "2  [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...             []   \n",
       "\n",
       "  prolific_authors  \n",
       "0         [42, 36]  \n",
       "1             [45]  \n",
       "2             [97]  "
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_prolific = train_df[train_df['prolific_authors'] != -1]\n",
    "train_df_noprolific = train_df[train_df['prolific_authors'] == -1]\n",
    "train_df_combine = pd.concat([train_df_prolific, train_df_noprolific.tail(3000)], axis=0)\n",
    "train_df_combine = train_df_combine.reset_index(drop=True)\n",
    "train_df_combine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "7b1aedb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[16336, 1762, 4357, 12564]</td>\n",
       "      <td>19</td>\n",
       "      <td>[37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...</td>\n",
       "      <td>223</td>\n",
       "      <td>[3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[21189, 14088]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...</td>\n",
       "      <td>223</td>\n",
       "      <td>[40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3625, 1198, 19889, 794, 2749, 7801]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...</td>\n",
       "      <td>7</td>\n",
       "      <td>[47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                             coauthors  year  \\\n",
       "0           0            [16336, 1762, 4357, 12564]    19   \n",
       "1           1                        [21189, 14088]    19   \n",
       "2           2  [3625, 1198, 19889, 794, 2749, 7801]    19   \n",
       "\n",
       "                                            abstract  venue  \\\n",
       "0  [37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...    223   \n",
       "1  [1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...    223   \n",
       "2  [1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...      7   \n",
       "\n",
       "                                               title  \n",
       "0  [3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...  \n",
       "1  [40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...  \n",
       "2  [47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...  "
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "8534a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, istrain):\n",
    "        self.data = dataframe\n",
    "        self.x = dataframe[['year', 'venue', 'coauthors', 'abstract', 'title']]\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = self.data.prolific_authors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        year = self.data.year[index]\n",
    "        venue = self.data.venue[index]\n",
    "        title = self.data.title[index]\n",
    "        \n",
    "        # word2vec on abstract\n",
    "        #abstractmodel = Word2Vec.load(\"abstract_word2vec.model\")\n",
    "        abstract = self.data.abstract[index]\n",
    "        #abstract_vector = abstractmodel.wv[abstract]\n",
    "        \n",
    "        # coauthors to one hot\n",
    "        coauthors = self.data.coauthors[index]\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if coauthors == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in coauthors:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "                \n",
    "        x_output = {\"title\": title, \"abstract\": abstract, \"year\": year, \"venue\": venue, \"coauthors\": coauthor_list}\n",
    "        \n",
    "        # target to one hot\n",
    "        if self.istrain == True:\n",
    "            prolific_list = [0] * n_prolific\n",
    "            if self.y[index] != -1:\n",
    "                for prolific in self.y[index]:\n",
    "                    prolific_list[prolific] = 1\n",
    "            y_output = prolific_list\n",
    "            return x_output, y_output\n",
    "        else:\n",
    "            return x_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "id": "74030042",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = AuthorDataset(train_df, istrain = True)\n",
    "testing_df = AuthorDataset(test_df, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "id": "0425b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"title\": [], \"abstract\": [], \"year\": [], \"venue\": [], \"coauthors\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            \n",
    "            output['title'] += [torch.tensor(x['title'], dtype=torch.long)]\n",
    "            output['abstract'] += [torch.tensor(x['abstract'], dtype=torch.long)]\n",
    "            output['year'] += [x['year']]\n",
    "            output['venue'] += [x['venue']]\n",
    "            output['coauthors'] += [torch.tensor(x['coauthors'], dtype=torch.long)]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['year'] = torch.tensor(output['year'], dtype=torch.long)\n",
    "        output['venue'] = torch.tensor(output['venue'], dtype=torch.long)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"title\": [], \"abstract\": [], \"year\": [], \"venue\": [], \"coauthors\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            output['title'] += [torch.tensor(data['title'], dtype=torch.long)]\n",
    "            output['abstract'] += [torch.tensor(data['abstract'], dtype=torch.long)]\n",
    "            output['year'] += [data['year']]\n",
    "            output['venue'] += [data['venue']]\n",
    "            output['coauthors'] += [torch.tensor(data['coauthors'], dtype=torch.long)]\n",
    "            \n",
    "        output['year'] = torch.tensor(output['year'], dtype=torch.long)\n",
    "        output['venue'] = torch.tensor(output['venue'], dtype=torch.long)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "b0a5e9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': [tensor([  46, 1910, 1553, 1942, 4365,    6,  114, 1558,   53, 1595, 1631, 1556,\n",
       "          1577, 3196, 1542,   51, 2427,   36, 1620, 1974,   51,  114, 1599, 1954,\n",
       "          1612, 2152,   11, 1847, 2541,  114,   51,    7, 1525, 2857]),\n",
       "  tensor([1708,   57, 2152,   57,   45,   37, 1632,   51, 1525,   40, 1621, 1536,\n",
       "          1751, 3363,   56, 1687, 1644]),\n",
       "  tensor([1560, 1570, 1681, 1553, 1535, 4905, 1569, 1820, 1549,   46, 1670, 1547,\n",
       "          1543, 1578, 1528, 1630,   56, 1633, 2160, 1525, 3368,   37, 1573, 1534,\n",
       "          1560,   34, 1555]),\n",
       "  tensor([  24,   50, 2374, 1608,   46, 1631, 4076, 4362,   53, 1759, 1992, 1549,\n",
       "            53, 2485, 1540, 1787]),\n",
       "  tensor([  47, 1603, 1538,   37, 1596, 1567,   37, 1632,   51,   56, 1633, 1579,\n",
       "          1658, 1530, 4070]),\n",
       "  tensor([  46, 1910, 1994, 2940,   36, 1664, 1820, 1708,   41, 1532, 1766, 1661,\n",
       "          1560, 1694, 1803, 1533, 1886, 2123, 2269, 1538]),\n",
       "  tensor([  40, 1560, 1536, 3485, 1573, 1678,   46, 1670, 1547, 1549, 1541, 1708,\n",
       "          1553, 2600, 2708,   46,   39, 1802]),\n",
       "  tensor([1563, 1594,   11, 3524, 1540, 2487, 1543, 1532, 1596,   53,   34, 1919,\n",
       "          1573,   11,   34, 1919, 1573, 1784,   41, 1589, 2687]),\n",
       "  tensor([3319, 2574,   54, 1551,   37, 1631, 1644, 1650, 1527,   37, 2085, 3073,\n",
       "          1979, 2904,   57, 1765]),\n",
       "  tensor([1654,   33, 1526, 2976, 1546,   41,   47, 1571, 1552,   35, 2032,   54,\n",
       "          2031,   24,   48, 2037, 4633, 1549,   40, 1733, 1735, 1540]),\n",
       "  tensor([  53, 1546, 1752,   37,   39, 1547, 1549, 1627, 3149, 1547,   37, 1631,\n",
       "          1644, 1525,   37, 1617, 2836, 2144, 1661, 1594]),\n",
       "  tensor([  11,   24,   46,   46, 1528, 1727, 1525, 2149,   48, 1559, 1623, 1546,\n",
       "          1803,   56, 1687, 1644, 1549, 1532,   41, 1820]),\n",
       "  tensor([1611, 2600, 1543, 1527, 1902, 1679,   24,   40, 1539,   33, 1565,   37,\n",
       "          2600, 4788, 2338,   51, 1684, 1708, 1549, 1609, 1538,   46, 1677, 1649,\n",
       "          3368, 1601, 2203, 3368, 4112,   57, 1548, 3391,   27]),\n",
       "  tensor([  33, 1526,   33,   33,   24, 1542, 1723, 1544, 3704, 1538, 1560, 1570,\n",
       "          1681, 1553,   48, 4590, 1707]),\n",
       "  tensor([1731,   53, 1584, 1529, 1589, 1629,   47, 1603,   24,   46, 1841, 2225,\n",
       "          1826, 1535,   38, 1592, 2938, 1543, 3413, 1568,   46, 1631, 2241, 1826,\n",
       "          1578, 1528, 2194, 1830, 1801, 1651, 2127]),\n",
       "  tensor([  37, 1631, 1644,   10, 1542, 2125, 1547, 1549,   50, 1589, 1575,   36,\n",
       "          1664, 1820, 1543, 1542, 1558, 2175, 1527, 1611, 3165, 1525,   40, 1621,\n",
       "          1536, 1542, 1558, 2175, 1541, 1708]),\n",
       "  tensor([  46, 1910,   46, 2421, 1543, 1527, 1743, 1551,   54, 1551,   33, 1660,\n",
       "            51, 1655, 1602,   45,   35, 1531, 1540]),\n",
       "  tensor([  37, 1595, 1536, 1635, 2106, 1549, 1621, 1541, 1745,   47, 1784, 1525,\n",
       "          1547, 1553, 2085, 1719, 1846, 1541, 1708]),\n",
       "  tensor([1544, 3927, 2686, 1543, 1535,   11, 3882,   13, 1533, 3691, 3037, 1527,\n",
       "            57,   46, 2497, 1549, 3485, 1573, 1678, 1525, 1716, 1528,   51, 1892,\n",
       "            50, 1620, 1632,   10,   28,   11, 3882,   10,   47, 1550, 1540, 1617,\n",
       "            10,   37,   55, 1533,   43,   10,   10, 2068, 1602,   16,   20,   10,\n",
       "          3882]),\n",
       "  tensor([1541, 1841, 1743, 1530, 1854, 2151, 3795, 1553, 1531, 1532, 1826, 1727,\n",
       "          4757, 1682, 1756, 1545, 1540, 1716, 1606, 1744,   37, 2247,   51]),\n",
       "  tensor([  55, 2793,   50, 1620, 1632, 1704,   50, 1620, 1632,   11, 3524, 2001,\n",
       "            11, 1538, 1723,   37, 1791, 1714]),\n",
       "  tensor([  47,   11,   37,   39, 3015, 1553, 2001,   11, 1529, 1589, 1629,   37,\n",
       "          2247, 1826, 1530, 2587]),\n",
       "  tensor([  47, 1568, 2039, 1745,   11, 3524, 1827, 1555,   47, 1603,   51, 1553,\n",
       "            50, 1620, 1632,   47, 1771,   36, 2107, 1547]),\n",
       "  tensor([  37, 2510, 1528, 1826, 4787, 2962, 1539, 1715]),\n",
       "  tensor([2134, 1534, 2201, 2686, 1543, 4019, 2547,   24, 1554, 2619, 1541, 1572,\n",
       "          1554, 3085,   51, 1631,   37, 1526]),\n",
       "  tensor([  46, 1910,   46, 2421, 1608, 3591, 1784, 1545, 1705,   51]),\n",
       "  tensor([  56,   48, 1549, 1538,   33, 2932, 1543, 2370, 1532, 1842, 1553, 4718,\n",
       "          1549, 4199, 1704, 2714, 2499]),\n",
       "  tensor([  53, 1584, 1903,   44, 1813, 1587,   45, 1553, 1532,   34, 1542, 2125,\n",
       "          1547, 1947, 1532, 1778,   44, 2818]),\n",
       "  tensor([  47,   55,   37, 1836, 1527, 2197, 1549, 2013,   41, 2317,   51, 1529,\n",
       "          1580, 1579, 1525,   47, 1785, 1532,   45,   37, 3878, 1537]),\n",
       "  tensor([1542,   43, 2904,   57, 1765, 1549, 1530, 1877, 1537,   24,   10,   33,\n",
       "            47, 1751, 2240, 1555, 1675, 1546, 1544, 2029, 1678, 1549, 3634, 1530,\n",
       "          1575,   53, 1526, 3012])],\n",
       " 'abstract': [tensor([  46, 1910, 1553, 1942, 4365, 1830, 1801, 1651, 4365, 3077, 1539, 3230,\n",
       "          1538, 1538, 1721, 4422, 3940, 1543, 2454,   12, 1731,   57, 1613, 3455,\n",
       "          1650, 1527, 2702,   25, 1535, 2885, 1542, 2178, 1546, 3767,   33, 4600,\n",
       "          1543, 2165, 1873, 1535, 2759, 2454,   12,   46, 1605, 1691,   10, 1557,\n",
       "          1917, 1546, 3140,   52, 1527, 2197, 1549, 2013,   41, 2317,   51,    6,\n",
       "             7,   10, 1706, 1860, 2867, 1931, 2698, 1525, 1910, 2719, 1978,   10,\n",
       "          1525, 1995, 1546, 3956, 1597, 1525, 3136, 1535, 4255, 2722, 1647, 3549,\n",
       "            12, 1606, 1701, 3561, 1525, 2758, 4468, 3403, 2719, 2694, 1527, 1535,\n",
       "          1659, 1546, 1580, 1867, 1579, 1546, 4111, 2192, 1578, 3438, 1525, 1535,\n",
       "          2719, 1543, 1535, 2454,   12,   37, 2227, 1672, 1605, 2090, 1720, 1580,\n",
       "          3558, 1549, 2087, 1563, 1527, 1810, 1758, 2592, 1978,   12, 1731, 1755,\n",
       "          2332, 1535, 4722, 1543, 1605, 2277, 1701,   10, 1706, 2477,   51, 2231,\n",
       "            33, 1877,   53, 1540, 1553, 2936, 1746, 4255, 1553, 2296, 2216, 1543,\n",
       "          3978, 1659,   12,   11,   24,  114, 1558,   53, 1595, 1631, 1556, 1577,\n",
       "          3196, 1542,   51, 2427,   10,   10, 2702,   10, 2167, 1645, 1528, 1930,\n",
       "          1629, 2152,   11, 1847, 2541,  114,   10, 1993,   36,  293, 1749, 1707,\n",
       "            12]),\n",
       "  tensor([3128, 1656, 1525,   40, 1621, 1536, 4949, 1993, 1542, 1546, 1874, 1913,\n",
       "          1535, 2650, 1549, 3006, 3180,   12,   47, 1548, 1927, 2044, 1905, 2504,\n",
       "          4923, 2575, 1535, 2021, 1543, 1609, 1738, 1546, 2741, 4954, 1608, 4003,\n",
       "          2662, 2614, 2009,   33, 2292, 1526, 1561, 4390,   12,   40, 1542, 1691,\n",
       "          2380,   33, 1692, 2219,   47, 1557,   52, 1542, 1857, 1546, 2463, 4792,\n",
       "          1704,   33, 2165, 2631,   12, 3524, 1527, 1843, 4936, 1758,   10, 1557,\n",
       "          1860, 3848, 2636, 4936, 1767, 4954, 1706, 2699,   45, 1682, 3895, 1580,\n",
       "          2636, 1704, 1535, 1927, 2044, 1701,   12,   37, 2578, 4792, 3428, 1546,\n",
       "          2051, 3039, 1630, 1546, 2741, 1840, 4936, 1767, 1630, 1825,   11, 3215,\n",
       "            12, 1606, 1888, 1808, 4937, 4093, 1807, 2663, 1586, 1557, 1720, 2741,\n",
       "          4936, 1767, 4954, 1586, 3431, 1608, 2233, 1876, 3337,   10, 2140, 3508,\n",
       "          2690, 1553, 4954, 1586, 3431, 2053, 1527, 1572, 1525, 1535, 1870, 1777,\n",
       "            12,   47, 1574, 4394, 1546,   33, 4949, 1993, 1642, 1650, 1527, 4923,\n",
       "            10, 1557, 1860, 3805, 1545, 1535, 2650, 3180, 1543,   18,   17,    4,\n",
       "          1527, 1630, 1825,   11, 3215, 1553,   33, 1777, 1543,   23, 3039, 1842,\n",
       "            10, 4467, 3921,    4, 2505, 1655, 2650, 3180, 1543, 4325,    4, 1525,\n",
       "          1535, 4923, 1642,   12, 1606, 1937, 1840,   10, 1563, 2713, 1535, 3006,\n",
       "          3180, 1543, 1630, 1825,   11, 2161, 4949, 1993, 1658, 4325,    4,   12]),\n",
       "  tensor([  46, 1605, 1691, 1557, 2227,   33, 2090, 1553, 4194, 1549, 3986,   39,\n",
       "            57,   48, 1528, 1529, 1560,   34, 1555, 1578, 1528, 1630,   56, 1633,\n",
       "          2160,    6,    7, 1525,   33, 4865, 2443, 1927, 2413,   12, 1731, 2090,\n",
       "          1806, 1719,   51, 1546, 1531, 1625, 1554,   51, 4636, 1901, 1758, 1553,\n",
       "          2051, 2504,   24,   33,   12, 3822, 4129, 1549, 4278, 3501, 1758,   25,\n",
       "            34,   12, 3009,   25,   35,   12, 3345, 1758, 1553, 1535, 2130, 1961,\n",
       "          1543, 1535, 3513,   25,   36,   12, 4331, 3501, 2003,   25,   37,   12,\n",
       "          1726, 2003, 3827, 1538, 1726, 3571, 1549, 1726, 1977,   25,   38,   12,\n",
       "          3916, 1543, 4462, 1752, 1641, 2219, 1557, 3525,   52,   33, 2256,   11,\n",
       "          1948, 4011, 2537,   25,   39,   12, 4772, 1758, 1525, 1535, 1624, 1543,\n",
       "          3923, 2939,   25,   40,   12,   47, 1679,   46,   52, 1549, 1861, 1560,\n",
       "            34, 1555, 3659, 2031, 1549,   46,   39, 1802, 2727,   10, 2236, 1658,\n",
       "          1645, 1679, 1538, 1604, 2413,   33, 2256,   11, 2248,  289,   39,   57,\n",
       "            48, 1528, 1529, 1560,   34, 1555,   10,   47, 1679,   46,   52, 1549,\n",
       "          1861, 1560,   34, 1555, 1549,   46,   39, 1802,  289, 1530, 2097, 1563,\n",
       "          2322, 1553,   51,   12]),\n",
       "  tensor([1587, 1721, 4330, 1660, 1707,   10, 3053, 2542, 1580,   33,   38, 2515,\n",
       "          1649, 1826, 1656, 1553, 2079, 3209,   12,   46, 1605, 2129,   10, 1557,\n",
       "          3041, 1549, 3558,   10,   33,   40, 1621, 1536, 2378, 1692, 3721, 1527,\n",
       "          1585,   11, 1525,   57, 1525, 1608, 4168, 4362, 3053, 4257, 1992,   12,\n",
       "            46, 2562, 1546, 4988, 2585,   40, 1621, 1536, 2378,   10, 4391, 4933,\n",
       "          1546,   51, 1612,   43, 2560,  293, 4330, 1660, 1707, 1658, 4238, 4333,\n",
       "          1913, 1630, 1948, 1549, 1916, 1948, 3053, 3311, 1787,   12, 1731, 1771,\n",
       "          3203, 1857, 1658,   10, 2504, 3624, 1962, 1682, 1549, 3724, 2352, 1842,\n",
       "          1650, 1527, 1630, 2484, 2246, 1549, 4238, 4333, 1882, 2530, 2352, 2047,\n",
       "          1650, 1527,   10, 1613, 4629, 1549, 3851,   12,   56, 1584,   41, 2762,\n",
       "          1755, 3206, 1586, 1720, 4645,   40, 1621, 1536, 3053, 1525, 1529, 2323,\n",
       "          1549, 1883, 1854, 4396,   12]),\n",
       "  tensor([  40, 1542, 1691, 3815, 1535, 2021, 1543, 3115, 1726, 1977, 4211, 1658,\n",
       "          1667, 4070, 1549, 1985,   51, 2044, 1772, 1754, 1553, 3115, 1535, 1977,\n",
       "            10, 1931, 3131, 1549, 1535, 1726, 2335, 1543, 1535, 3131,   12,   37,\n",
       "          3767, 1529, 4982, 2322, 1543,   17,   16, 1977,   10, 2864, 1527, 1535,\n",
       "          1630, 2135, 2475, 1656, 1553, 1667, 4070, 1549, 3771, 1566, 1708, 2352,\n",
       "          3113, 2466, 1667, 4070,   12,   41, 1877,   33, 4844, 1525,   33, 1916,\n",
       "            10, 1604, 2443, 1656, 1546, 3415, 1607, 1535, 4844, 1799, 1549, 1898,\n",
       "          3131, 3453, 1608, 1931, 1726, 2335,   10, 1554,   33, 2248, 1546, 2561,\n",
       "          1535, 1799, 2523,   12, 1731, 2235, 1659,   10, 2172,   10, 2053, 2776,\n",
       "          2939, 1553, 1535, 1799, 2334,   10, 1549, 1670, 1535, 3131, 1549, 2335,\n",
       "            12,   37, 2746, 1605, 1658, 1662, 1538, 1810, 1754, 1553, 4844, 1799,\n",
       "          2719,   12, 1606, 4185, 1543, 2787, 1961, 4028, 3494, 1546, 4585,    4,\n",
       "          2059, 1527, 1799, 2719,   12, 1606, 1937,   10, 1658, 3415, 3115, 1535,\n",
       "          1799,   10, 3131,   10, 1549, 1931, 2335, 3453, 1608, 4844, 2135,   10,\n",
       "          1557, 1712, 1586, 1557, 1720, 1670, 2053, 1874, 1535, 1799, 2059,   10,\n",
       "          1935, 1878, 2411, 1874, 2135, 2523, 2059,   12]),\n",
       "  tensor([  37, 1662,   33, 2095, 1701, 1546, 1824, 3842, 2431,   10, 1586, 2065,\n",
       "          2063, 1913, 3842, 1661, 4989, 1549, 3842, 1661, 2547, 1525, 1609, 4145,\n",
       "          1647,   12, 1606, 1642, 1984, 3197, 2841, 2008, 3910, 1886, 2702,    6,\n",
       "             7, 1543, 3457, 1549, 2178, 1868, 1540, 1535, 3027, 2008, 1553, 3842,\n",
       "          1661, 2901, 2210, 1873, 3181,   12,   52, 2178, 3120, 1793, 1543, 1535,\n",
       "          4210, 1551, 1800, 1543, 1535, 3842, 2491, 2901, 1982, 3532, 1546, 2226,\n",
       "          1535, 1803, 1723, 3842, 1661, 2547,   12,   46, 3340, 1546, 2118, 1681,\n",
       "            10, 1604, 1692, 1542, 2743, 2277,   12, 1540, 3787, 1605, 2309,   10,\n",
       "          1563, 2781, 1988, 1608, 1529, 4105, 2802, 2650,    6,   14,   12,   20,\n",
       "            23,    7, 1549, 3006,    6,   14,   12,   20,   15,    7,   12, 1606,\n",
       "          1701, 1542, 1878, 1535, 1984, 1859, 1525, 1546, 3564, 1535, 4002, 3933,\n",
       "          1527, 1535, 3164, 1525, 3102, 3367, 1543, 3389, 1549, 1577, 4373, 3181,\n",
       "          1525, 1535, 1997, 3884, 1525,   12]),\n",
       "  tensor([2600, 2708,   46,   39, 1802, 2512, 3683, 2819, 2566, 1608, 3345, 3599,\n",
       "          1843, 1554, 2013, 1542, 2160,   10, 1525, 1875, 1787,   10, 3915, 1787,\n",
       "            10, 1549, 1630, 1995, 2566,   12, 1731, 1536, 2566, 1613, 1670, 1558,\n",
       "          1565, 1920, 1658, 1535, 2267, 1882,   11, 2715, 2040,    6,    7, 2433,\n",
       "            12, 3158, 2718,   10, 1563, 1542, 1670, 1539, 1733, 2014, 3413, 4100,\n",
       "          1672, 1546, 4358, 3669,   46,   39, 1802, 1608, 2130, 2471,   12,   37,\n",
       "          2750, 1543, 1605, 3726, 1547,   10, 2236, 1866, 2000, 4467, 1591, 1681,\n",
       "          1527, 2130, 1961, 2036, 1553, 3669, 2076, 3788, 1898, 3621, 1549, 4722,\n",
       "            12,   47, 2746, 1605, 3400,   10, 1557, 1917,   33, 2130, 1961, 2036,\n",
       "          3038, 1553, 3669,   46,   39, 1802,   10, 1586, 3561, 1543, 3747, 3658,\n",
       "          4027,   12,   37, 2545, 1535, 2036, 3038, 1546, 1810, 1858, 3669, 2076,\n",
       "          1549, 1712,    6,   41,    7, 1898, 2952, 1539, 4386, 3986, 3669,   46,\n",
       "            39, 1802, 1608, 2130, 1961,    6,   41,   12,   37,   12,   10, 1970,\n",
       "          1834,   11, 4013, 3034,    7,   25,    6, 3043,    7, 1535, 3345, 3599,\n",
       "             6, 2433,    7, 1543, 3669,   46,   39, 1802, 2675, 1655, 1535, 2235,\n",
       "          2076,   25, 1549,    6, 3043,   41,    7, 2130, 1961, 1904, 1848, 1527,\n",
       "          3669,   46,   39, 1802, 1553, 1535, 1984, 2116,   12,   37, 1878, 2362,\n",
       "          2574, 1535, 2036, 4533,   10, 1535, 2235, 1659,   10, 1549, 1535, 2212,\n",
       "          1607, 1546, 1535, 3010,   12]),\n",
       "  tensor([  37, 1662,   33, 1692, 1553, 2353, 1826, 1962, 2813, 2088, 1655, 1962,\n",
       "          4050,    6,   33, 4699, 3900,    7, 1525, 1532, 1596, 2047, 4244, 1655,\n",
       "          1529,   46,   39, 1802,   11, 1532, 1596, 3281, 1594,   12,   37, 3564,\n",
       "          1535, 2309, 1586, 3877, 1549, 3993, 1613, 3455, 3643, 2862, 1816, 1525,\n",
       "            46,   39, 1802,   12,   37, 1712, 1586,   33, 2305, 1692, 2353, 1988,\n",
       "          2140, 3877,   11, 3993, 2125, 2687, 1525, 1532, 1596,   10, 2187, 3263,\n",
       "          3300, 2566,   12,   37, 2247, 1605, 3596, 1554, 1535, 1984, 2582, 1525,\n",
       "          2138, 2544, 3904,    6, 4777,    7, 2657, 2474, 1659,   12,   37, 1878,\n",
       "          2368, 1704, 1563, 1546, 1874,   33, 1900, 1543, 1535, 1943, 2044, 2212,\n",
       "            12]),\n",
       "  tensor([  47, 3357, 2752, 1866, 4612, 1982, 2490, 2892, 1543, 1898, 3094, 1553,\n",
       "          1993, 1543, 1758, 1543, 2386, 2335,   12, 1533, 2968,   10, 1758, 3731,\n",
       "          1655,   55, 2793, 3763, 1585, 1546, 2888, 2548, 2399, 1843, 1554, 3115,\n",
       "          1529, 2085, 2711, 3132, 1543, 3550, 1531,   58,   33,   12,   47, 2171,\n",
       "            10, 1704, 1647, 1758, 1655, 2481, 2752, 1601, 1684, 3166, 1553, 2330,\n",
       "          2274, 2892, 1543, 1535, 1609, 4089, 3868, 1543, 2229,   11, 2565, 2228,\n",
       "            10, 1706, 2512, 3290, 4715,   11, 2309, 1723, 1900, 1710,   12, 1527,\n",
       "          2093, 2977,   10, 1605, 2129, 3133, 1535, 1793, 1543, 2436, 1979, 1800,\n",
       "          1546, 1874, 4768, 2574, 2330, 2274, 1655,   55, 2793, 4248,   10, 1533,\n",
       "           295, 3030,  296,   12,   56, 1584,   41, 2762, 1755, 2332, 1586, 1535,\n",
       "          2642, 1543,   33, 2436, 1979, 2932, 1549,   33, 2436, 1979, 4704, 2713,\n",
       "          1535,   15,   11, 2328, 1658,   17,   12,   19, 3156,   12]),\n",
       "  tensor([1731, 2992, 1543, 3714, 2976, 1542,   33, 3080, 2647, 1543, 1662,   11,\n",
       "          4066, 3527, 2099,   12,   57,   48, 1661, 3714, 2976, 2780, 1565, 1975,\n",
       "          2287, 1724, 1543, 2454, 1543, 2386, 2335, 4052, 4989, 1613, 3937, 1554,\n",
       "          1530, 4061, 4281, 4651, 2287, 1724, 1543, 1530, 1803, 2826,   10, 3806,\n",
       "          1549, 3649,   41, 1724,   12,   46, 2586, 3152,   10, 3300, 1758, 1993,\n",
       "          2096, 2451, 4494, 1543, 3664, 2179, 1535, 1948, 1543, 3117, 1525, 1647,\n",
       "          3610, 1546, 2561, 1535, 2036, 1543, 1843, 3714, 2248, 2216,   12,   37,\n",
       "          3843, 1586, 2330, 2216, 1543, 1535, 2456, 3395, 2193, 1658, 1535,   41,\n",
       "            47,   40, 1986, 1653, 1613, 4501, 4941, 1553, 3714, 2248, 2036, 2561,\n",
       "            12,   51,   33, 2582, 2700, 2337, 2526, 1605, 4270, 3134,   10, 1557,\n",
       "          2129, 1535, 3428, 1655,   33, 2692, 3714, 2248, 2246, 1546, 1535, 2330,\n",
       "          2246, 1525, 1995, 1546, 2226, 1530, 1583, 1746, 3166, 1525, 2330, 1993,\n",
       "          1553, 3714, 2248, 2036, 2561,   12, 1751, 1876, 1538, 3321, 1896,   10,\n",
       "          1557, 1662,   33, 4006, 2129, 1543, 4659, 1525, 3943, 1549, 1665, 2101,\n",
       "          1547, 1530, 4061,   10, 1741, 1708,   33, 1814, 2330, 2634, 1549, 2246,\n",
       "          1553, 1535, 4442, 1549,   10, 1554,   33, 2582, 2700, 1898, 1824, 1993,\n",
       "            10, 2434,   33, 2821, 2235, 2413, 3540, 1535, 2456, 2722,   33, 4663,\n",
       "          1543, 3955, 1568, 4173, 2492, 2235, 2330, 3265,   12,   51,   33, 2271,\n",
       "          3602, 3838,   10, 1557, 2434, 1535, 1984, 3714, 2248,   11, 1546,   11,\n",
       "          2330, 4183, 4137, 1553,   13,   37, 1836, 1540, 1863, 1532, 3714, 2976,\n",
       "          1549, 2827, 1535, 1827, 2037, 4633, 1541, 3361, 1655, 1535, 2188, 1546,\n",
       "          3470,   52, 1535, 3855, 2267, 3714, 2248, 2285, 1546, 2671,   12]),\n",
       "  tensor([1731, 1824, 2274, 1543, 4199, 1549, 1711, 3149, 1547, 1525, 3551, 1670,\n",
       "          1540, 1542,   54, 3348, 2094, 1868, 1538, 1553, 1685,   53, 1621, 3265,\n",
       "          1543,   33, 2292, 4773,   12,   40, 1542, 1691, 2449,   33, 1814, 1807,\n",
       "          1543, 4199, 1549, 1711, 3149, 1547, 1659,   10, 1525, 1535, 1565, 1617,\n",
       "          2836, 3551, 1591, 1631, 1837,   10, 1549, 2449,   33, 3971, 1543, 2002,\n",
       "          2219, 1658, 1557, 2037,   33,   11, 1650, 1692, 2466, 1655, 1535,   41,\n",
       "            47, 1558, 1627, 1807, 1546, 1605, 2095, 1837,   12]),\n",
       "  tensor([  40, 1542, 3205, 2380, 1535,   11, 1642, 1553, 1535, 1803,   56, 1687,\n",
       "          1644, 1549,   41, 1820,    6,    7,   40, 1986, 1653,   12,   52, 3561,\n",
       "          1543, 2256, 3036,   24,   15,    7,   41,   43, 2083, 2748, 1629,   37,\n",
       "          1791, 1714,   24, 1660, 1548, 1557, 2741, 1535, 2454, 1525, 1535, 4449,\n",
       "            10, 2178, 1557, 2463, 3094,   41,   43, 2083, 2748, 3542, 1553, 2051,\n",
       "          1543, 1535, 2454, 1704,   33, 2645, 1808,   48, 2748,   16,    7, 1551,\n",
       "          1728, 2445,   24,   37, 2611, 2386, 2298,   41,   12,   37,   12, 1571,\n",
       "          1739,   46, 1595, 1536, 2020, 1846,    6,    7,   10, 3591, 1808,  293,\n",
       "            51, 2404, 1992,    6,    7,   10, 1543,   52,   11, 2016, 1621, 1637,\n",
       "          1602, 1541, 1641,   10, 2016, 1621, 2165, 1608, 2183, 2161, 1532,   45,\n",
       "          2020, 1846,   46, 1595, 1536,   47, 1730, 1575, 2020, 1846,    6,   11,\n",
       "             7, 1546, 2136, 2047, 1658, 1931, 2165, 1546, 1535, 4449,   12,   17,\n",
       "             7, 1594, 1723,   46, 3001, 1575,   24,   37, 2677, 2256, 1754, 1553,\n",
       "          1535, 1656, 1543, 4449, 2003,   12,   37, 2545,   33,   37, 1625, 2016,\n",
       "          1738,   52, 1902, 1537,    6,    7, 1607,    6, 1756,   43,   40, 1994,\n",
       "          1534,   12,   10, 3238,    7,   10,   33,   37, 4734, 1560, 1694,   46,\n",
       "          3001, 1575,    6,    7, 1607,    6, 4885, 1994, 1534,   12,   10, 3521,\n",
       "             7, 1549,   33, 1560, 1593, 1551,   11, 2174, 1548, 1545,   37, 2299,\n",
       "          1530, 1540,    6, 1534, 2016, 1745,    7, 1607,    6,   37, 1529, 1994,\n",
       "          1534,   12,   10, 3776,    7, 1553, 1605, 1656,   12, 1731, 2002, 1712,\n",
       "          1586, 1535, 3723, 1608, 2305, 2016, 1621, 1637, 1602, 1541, 1641, 1704,\n",
       "          1525, 1916, 2445, 3453, 1608, 1607, 1554, 2334, 1689, 1607, 2525, 1535,\n",
       "          2146, 1755, 1527, 1535, 2610, 1777,    6,   15, 3125,   24,   17,   16,\n",
       "            12, 4535,   10, 2334, 2059,   24,   19,   23,   12,   20,   15, 1549,\n",
       "          2328,   24,   14,   12,   17,   21,   21,   22,    7,   12, 1606, 1937,\n",
       "          1840,   10, 1563, 2811,   51, 4325,   12, 2616,   10,   18,   22,   12,\n",
       "          4810, 1549,   17,   20,   12,   19,   19, 1525, 2342, 1543,   15, 3125,\n",
       "            10, 2334, 2059, 1549, 2328,   10, 3314,   10, 1527, 1535, 2124, 1777,\n",
       "            12, 1606, 1642, 2136,   51, 4108, 1526, 2722,   16,   17, 3566, 1525,\n",
       "          1535, 2223, 1656, 3160, 1546, 2455, 1997,   11, 1888, 1543, 1535, 3125,\n",
       "            12]),\n",
       "  tensor([3449,   12, 1525, 1572, 1525, 2128, 1537, 1543, 1527, 1902, 1679,   10,\n",
       "            33, 1811, 1772, 1692, 4441, 1588, 1920, 1553, 3427,   11, 3505, 2015,\n",
       "          2942, 3263, 1525, 3135, 1649, 3368, 2640, 2993, 1839,   10, 1563, 2294,\n",
       "          1544,   44, 1801, 1721, 1525, 1808, 2158, 3265, 2377, 1721, 1604, 2399,\n",
       "          2066, 3955, 1568,   18,   14, 3988, 2385,   51,   12, 1731, 1862, 3274,\n",
       "          1543, 1605, 1659,   11, 2965, 1692, 1542,   33, 2411, 4846, 1642, 1848,\n",
       "          2496, 1746, 2338, 4868,   10, 3687, 2913, 3204, 2385,   51, 3999, 1955,\n",
       "          1526,   12]),\n",
       "  tensor([  46, 1605, 1691,   10, 1557, 1662,   33, 1526,   33,   33,   15,   10,\n",
       "          1529, 2477, 2155, 2180, 1650, 1542, 1723, 1544, 3704, 1538, 1560, 1570,\n",
       "          1681, 1553, 2399,   12,   52, 4682, 2430,   10, 1564,   37, 1730, 1537,\n",
       "          1549, 1896, 1543, 2296, 1839, 1658, 4400, 1708, 1549, 2541, 2530, 2901,\n",
       "          2208, 4485, 1655, 1529, 4455, 2293, 1549, 3643, 2584, 2415,   47, 1677,\n",
       "          1552, 1747, 3230, 1869,   12,   52, 1754, 1839, 1554,   33, 4317, 1982,\n",
       "          1734, 1646, 1555, 1560, 1694, 1543, 1827, 1537, 1682, 1612, 1733, 1534,\n",
       "          2193, 1758, 4631,   10, 1549, 1552, 1610, 1535, 2229, 4400, 1536, 1549,\n",
       "          1793, 2293, 4485, 1525, 1931, 2399, 1660, 3109, 1864, 1543, 1931, 4409,\n",
       "          3406, 4869, 1846,   12,   33, 1526,   33,   33, 1564, 1601, 1684,   33,\n",
       "          4970,   47, 1677, 1552, 4001, 1546, 2211, 3753, 4077, 1543, 3689, 3036,\n",
       "             6, 3453, 1608, 1931, 3379, 3646, 3333, 1554, 1663, 2064, 1532, 2909,\n",
       "          1724,    7,   10, 1563, 2795, 3999, 1859, 1546, 2641, 1802, 1931, 3646,\n",
       "          3333, 1525,   33, 1932, 1541, 1593,   58, 1545, 4166, 1553, 3999, 1859,\n",
       "          3071, 1536, 1546, 1793, 1563, 1721, 1543, 1535, 2519,   56,   12]),\n",
       "  tensor([1814, 4467,   11, 1904, 1669, 1607, 3540, 2316, 1942, 3198, 1586, 1542,\n",
       "          1650, 4420, 1535, 2786, 1543, 4004, 2085, 1719, 1846, 1560, 1828,   51,\n",
       "          1542, 3232, 1525, 1605, 1691,   12, 1564, 1661, 1800, 1549, 1962, 2822,\n",
       "          1613, 1528, 2204, 1568, 3702, 1947,   33, 2183, 1624, 1901, 1961, 3261,\n",
       "            33,   53, 1584, 1586, 1542, 3379, 1608,   33, 1630, 1525, 1535, 2339,\n",
       "            12, 1731,   53, 1584, 1669, 1607, 4955, 4980, 1729, 1641, 1549, 1630,\n",
       "          2343, 3180, 2516, 1546, 1791, 2161,   10, 2276,   11, 1543,   11, 2038,\n",
       "            11, 1650,   10, 1549, 2212,   11, 1650, 1669, 1754,   12, 1731, 2723,\n",
       "          4889, 1543, 1535, 2386, 1942, 3198, 1546, 1535, 4383, 1543, 1604, 1607,\n",
       "          1613, 1878, 4591, 1658, 1704, 4004, 2583,   56, 1547, 1539, 1535, 1948,\n",
       "          1543, 1535, 1942, 3198,   12,   37, 1860, 2817, 1586, 3243, 2051, 1942,\n",
       "          2155, 1577, 3572, 1546, 1669, 1607, 2115,   10, 1927, 1800, 1613, 1529,\n",
       "          1721, 1932, 1538, 1577, 2761, 1533, 2094, 2198, 1613, 1528, 2204, 1568,\n",
       "          3702, 1608, 1630, 1906, 1727, 1549, 1962, 2822,   12, 1606, 4770, 1878,\n",
       "          4310, 2649, 2792,   51, 1553, 1535, 3451, 3924, 1848, 1543, 2244, 2831,\n",
       "          2012, 2040, 1754, 1525, 1535, 3301,   12]),\n",
       "  tensor([  46, 1605, 1691,   10, 1557, 2611, 2876, 2340, 3143, 3436, 1553, 2886,\n",
       "          2206, 1799, 2334, 1689, 1525,   40, 1621, 1536, 2228,   24,    6,   15,\n",
       "             7, 2206, 2901, 1864, 1594, 1560, 1644,   10,    6,   16,    7, 3492,\n",
       "          3900, 2653,   10,    6,   17,    7, 1799, 2456, 2475,   10, 1549,    6,\n",
       "            18,    7, 2502,   34, 1829,   36, 1869, 2431,   12,   46,   33, 3381,\n",
       "            44, 1816,   40, 1621, 1536, 2206, 2212,   10, 1557, 2226, 3094, 2901,\n",
       "          1864, 3542, 1658, 3250, 3225,   10,   37, 2314, 1525, 1597, 2152,   11,\n",
       "          2206, 1585, 1821, 1655, 2307, 1608,   33, 3812, 1809, 1790, 1532,   10,\n",
       "          3664, 1565, 3492, 2125, 2687, 2722, 2901, 1864, 3036, 1658, 2489,   10,\n",
       "          2353, 1597, 2583, 1537, 2335, 1658,   33, 1789, 2248, 2556,   10, 1549,\n",
       "          3668, 1535, 2502, 4398, 1658, 3201, 1560,   46, 1663,   45, 3571,   12,\n",
       "          1731, 2002, 1527,   40, 1621, 1536, 1542, 1558, 2175, 1745, 2243, 1712,\n",
       "          1586, 1535,   15, 2655, 1543,   14,   12,   21, 3921,   20,   10,   14,\n",
       "            12,   21,   20, 3147,   10,   14,   12,   21,   18,   19,   22,   10,\n",
       "          1549,   14,   12,   17, 4173,   18, 1613, 2807, 1553, 2206, 3923, 2475,\n",
       "            10, 2815, 1525,   39, 2475,   10, 1799, 2456, 2475,   10, 1549, 2502,\n",
       "          4932, 2431,   10, 3109,   35, 2664, 1568,   10, 1525,   33, 3381,   44,\n",
       "          1816,   40, 1621, 1536, 2206, 2212,   12]),\n",
       "  tensor([  53, 1596, 1735, 4084, 1525, 4484, 1542, 4814, 2965, 1658, 3667, 2338,\n",
       "          2206, 1977, 1873, 4484, 2671,   10, 1549, 1535, 4377, 1707, 2338, 2695,\n",
       "          1542, 3847, 1546,   40, 2167, 1531, 4283, 1586, 1755, 1655, 1843, 3667,\n",
       "            12,   37, 1868, 1724, 1525, 1860, 3909, 1801, 2410, 1843, 4377, 1707,\n",
       "          1655,   33, 2896, 1543, 3619, 3165,   10, 2504, 2315, 1826, 1563, 1554,\n",
       "          1535, 2534, 1543, 1535, 2206, 1799,   10, 1533, 1554,   33, 2456, 1543,\n",
       "          2585,   11, 2135, 4787, 3667,   12, 1606, 1701, 1542, 1546, 1607, 4273,\n",
       "          1873, 2671, 1658, 4897, 1538, 1527, 2244, 1543, 1845, 2816, 1543, 2118,\n",
       "          1681,   12,   37, 2522, 1549, 2368, 1858, 2277, 1905, 1553, 1772, 2330,\n",
       "          2289, 1586, 1613, 3847, 1546, 1580, 1527, 1859, 3393,   12,   37, 4883,\n",
       "          2330, 2289, 1586, 1557, 1703, 1655,   33, 1807, 1543, 2843,   45, 3185,\n",
       "            37, 3307, 4821, 2180, 1868, 4669,   10, 1549, 2368, 1604, 1755, 1658,\n",
       "          2333, 2208, 1997, 4085, 1543, 1577, 1743, 1846,   12, 1606, 1755, 3625,\n",
       "          1586, 1535, 1793, 1543, 2180, 1868, 4669, 4708, 1535, 3190, 2059, 1543,\n",
       "          1604, 2146, 1692, 1546, 4854,   12,   20,   18,    4, 1808,   33, 2297,\n",
       "          1543, 3921,    4,   10, 1554, 2516, 1546, 1529, 3190, 2059, 1543, 4976,\n",
       "            12, 4108,    4, 2458, 2180, 1868,   12]),\n",
       "  tensor([  37, 2915, 1773, 3673,   11, 1650, 1618, 3289,   13, 4260, 1572, 2012,\n",
       "          2846, 2682, 2512, 2279, 3661, 1525, 1535, 1896, 1543, 2612, 2905, 2844,\n",
       "             6, 1577, 1534,   36,    5,   41,   54, 1530,   10, 3882,    7,   12]),\n",
       "  tensor([1731,   11, 3882,   13, 1533, 3691, 3037, 1527,   57,   46, 2497, 1549,\n",
       "          3485, 1573, 1678, 1525, 1716, 1528,   51, 1892,   50, 1620, 1632,    6,\n",
       "             7, 1546, 3296, 3526, 1527,   16,   20, 2068, 1602, 3882, 3752, 1535,\n",
       "            11, 4438, 1616, 1548, 1545, 1658, 1535, 2035, 4628, 1543,   47, 1550,\n",
       "          1540, 1617, 1525,   37,   55, 1533,   43,   12,   52, 2294, 3102, 2193,\n",
       "          1525, 3828, 1546, 4943, 2698, 1525, 2044,   10, 1957, 2709, 1754, 1543,\n",
       "          1977, 1873, 2007, 1907,   12, 1606, 1616, 1627, 2294, 1546, 3230, 1538,\n",
       "          3436, 3502, 4578, 1527, 2386, 3079, 1543, 1605, 3877,   10, 1549, 4703,\n",
       "          1655, 2386, 1687, 3968,   12, 1611, 2248, 1586, 1535, 4639, 1543, 1845,\n",
       "          1687, 3968, 1720, 1580, 3366, 1542, 1525, 1931, 1591, 2281, 1646, 3212,\n",
       "            24, 1648, 2421, 2693, 2863, 1675, 1525, 2692, 1669, 3335,    6,   37,\n",
       "            55, 1542, 1549, 1631, 1541, 4454, 2616,   20,   22,   10, 1616, 1549,\n",
       "          1836, 1596, 2616,   20,   23,    7,   10, 1549, 1554, 2698, 1525, 2307,\n",
       "          2294, 1530, 1814, 1545, 1525, 1535, 2443, 2960, 3301, 1525, 1535, 3302,\n",
       "            14,   51,   10, 2198,   35, 1953, 1546, 1580, 1878, 2685, 1554, 4035,\n",
       "          2693,   12, 1585,   40, 3442, 3969, 4946, 1549, 1957, 3969, 4946,   10,\n",
       "          1878, 3869, 1525, 1535, 3024, 2616, 4937,   51,   10, 1615, 2519, 2738,\n",
       "            33, 2668, 1556, 1646, 1541, 1854,   10, 3378, 1840, 3139, 1740, 2247,\n",
       "            10, 1935,   10, 1525, 2231, 3272,   10, 1860, 1648, 2421,   11, 2040,\n",
       "          3659, 2031,   12, 1591, 1937, 3636, 1543, 4639, 1542, 1535, 3063, 1543,\n",
       "          2399, 1543, 4035,   13, 1648, 2421, 2693,   10, 1706, 1542, 2355, 1568,\n",
       "          4170, 1982, 1525, 1604, 3282, 4443,   12,   37, 3764, 2876, 1631, 1531,\n",
       "          3583,   10, 1706, 3290, 3583, 1527, 2692, 2949, 1543, 4035,   13, 1648,\n",
       "          2421, 2693, 1655, 1913, 4236,    6, 1618,   37, 3507,    7, 1549, 4068,\n",
       "          2356,    6,   40, 3766, 1549, 1602, 1556,   33,   25,   53, 3766,   25,\n",
       "          1530,   57, 1532,   10, 1733, 1549,   40, 1918, 1529, 3013,    7, 3619,\n",
       "          3165,   10, 1549, 3583, 3493, 4035,   13, 1648, 2421, 2693, 1546, 1811,\n",
       "          1700, 1554, 2050, 1554, 2163,    6, 1733, 1549, 2788,   35,    7, 1549,\n",
       "          1726, 3405,    6, 1853, 1527, 1549, 1618,   37, 3507,    7,   12, 1731,\n",
       "          2553, 2494, 3944, 1553, 1535, 3282, 2294, 1602, 1747, 1697,   12, 2111,\n",
       "            51, 1543, 1535, 2035, 4628, 1543,   41, 1550,   41, 2963,   10,   33,\n",
       "          2554, 1859, 1532, 1543, 1957,   11, 3969, 2501, 3335, 2730, 2294, 1859,\n",
       "          1543, 1535, 1984, 1546, 2717, 1535, 4722, 1543, 1957, 3969, 4946, 1553,\n",
       "          2007, 1669,   12]),\n",
       "  tensor([2455, 1543, 1535, 1883, 1854, 1549, 3607, 1560, 1639, 4123, 1586, 2682,\n",
       "          1669, 1564,   35, 2374, 1613, 1588, 1548, 1525, 1700, 1525, 2234, 2007,\n",
       "          1669, 2163, 1735, 2854,   12,   46, 1605, 1691,   10, 1557, 2717,   33,\n",
       "          1692, 1546, 3892,   54, 1770, 4674, 1655, 3394, 1549, 3384, 3382, 1525,\n",
       "          1535, 2412,   33, 1606, 1744, 1837,   10, 1608, 1535, 3029, 1543,   54,\n",
       "          3585, 1568, 4402, 1538, 1535, 2335, 1543, 2871, 4757, 3824, 2293, 1546,\n",
       "          1535, 2007, 1669, 4981,   12,   37, 1703, 3478,   34, 1751, 1555, 3758,\n",
       "          1864, 2558, 1586, 1613, 1822, 1854, 1543, 1535, 2773, 1568,   11, 1966,\n",
       "          1531, 2029, 2143, 2262, 1669, 4240, 1857, 1525, 3309, 3394, 1533, 3384,\n",
       "          3382,   12,   37, 2178, 2226, 1549, 1556, 1927, 2409, 2454,   10, 1549,\n",
       "          1793, 4829, 1546, 2741, 2163, 4674, 1655, 2726, 2047,   12,   37, 2368,\n",
       "          1535, 2930, 4674, 3295, 1840, 2922, 2726, 4674,   10, 1704, 4763, 2755,\n",
       "          1543, 3179, 1525, 2446, 2469,   10, 3773, 2469,   10, 1549, 2007, 2469,\n",
       "            12, 1606, 1755, 1712, 1586, 1535, 2930, 4674, 2328, 3187, 1527, 1845,\n",
       "          2755,   12, 1525, 1682,   10, 1557, 3370, 1535, 1901, 3021, 1586, 2282,\n",
       "          2409, 1535, 2930, 3394, 1549, 3384, 4674,   12,   37, 3738, 1546, 1793,\n",
       "          1535, 2930, 4674, 1546, 1874, 1535, 3567, 3355, 1543, 2185, 1839, 1525,\n",
       "          1535, 2412,   33, 1606, 1744, 1837,   12]),\n",
       "  tensor([1555, 1544, 3429, 2802, 3646, 3333, 1843, 1554,   55, 2793, 1860, 4012,\n",
       "          3395, 2752, 1553, 2337,   11, 2116, 2229, 3560, 2389, 1530, 4334,   12,\n",
       "            53, 1550, 3998, 2512,   40, 2167, 1531,   51, 1525, 2304, 1525, 1858,\n",
       "          1907,   10,   37,   12,   39,   12,   10, 4503, 4063, 2352, 1546, 1535,\n",
       "          2403, 2671, 1543, 1535, 1560,   34,   51, 2068, 1538, 2451, 3075, 1525,\n",
       "          1560,   34, 1555, 1549, 1525,   46,   39, 1802,   12, 1731, 3029, 1543,\n",
       "          1605, 1691, 1542, 1546, 3564, 1605, 2304, 2697, 1525, 1995, 1546,   37,\n",
       "          2314, 1525, 1597, 1535, 1771, 3563,   52, 4855,   37, 2064, 1525, 1824,\n",
       "            55, 2793, 1700,   10, 3873, 1535, 3277, 1543, 2464, 1916, 2289, 1553,\n",
       "          1870, 1839,   12,   37, 1712, 1586, 1700,   11, 1650, 2258,   11, 2039,\n",
       "          1758, 2592, 1720, 2418, 2419, 4503, 4248, 2466, 1907, 1586, 1613, 1971,\n",
       "          4505, 1546, 1580, 1857, 1546, 2767,   33, 2195, 2130,   11, 1650, 3723,\n",
       "            12, 1606, 1692, 2429, 1969, 2096, 1546, 1837, 2771, 1553, 1843, 1554,\n",
       "          1669, 1607, 2771,   10, 4417,   11, 3798, 4015,   10, 1533, 3067,   11,\n",
       "          1700,   12]),\n",
       "  tensor([1731, 1656, 1543, 2726, 4011, 2523, 1720, 1580, 2050, 4828, 1658, 1704,\n",
       "          3662, 2498, 2810, 2236, 1542,   33, 4089, 1870, 1777, 1543, 3382, 1608,\n",
       "          1997, 4650,   12,   46, 1605, 1691,   10, 1557, 2369, 1546, 2611,   33,\n",
       "          1840, 3128, 1656, 1543, 2258, 1669, 2726, 4011, 2523,   10, 1706, 3120,\n",
       "          1793, 1543, 2053,   50, 1675, 3382, 1525,   33, 2155, 1669,    6,   37,\n",
       "            12,   39,   12,   46,   39, 1802,    7, 1546, 2791, 1535, 4011, 2655,\n",
       "          1543, 1609,   50, 1675, 3382, 1525,   33, 2186, 1669,    6,   37,   12,\n",
       "            39,   12, 1532, 1596,    7,   12,   37, 1917,   33, 1814, 1558, 3662,\n",
       "          2072, 1546, 2746, 1605, 1656, 1658, 4282, 3399, 3382,   12, 2796, 1547,\n",
       "          1755, 1527, 2244, 2407, 1712, 1586, 1604, 2046, 1558,   11, 3662, 2072,\n",
       "          1720, 4386, 1874, 1535, 2523, 1755,   12]),\n",
       "  tensor([1827, 1555, 1754,   10, 1529, 2277, 2834, 1553, 2603, 3280, 1700, 2609,\n",
       "          1874, 1811, 1700, 2115,   12,   47, 2171,   10, 2118, 1681, 2452, 2053,\n",
       "          1535, 2155, 1669, 1549, 3328, 1568, 4602, 1591, 1561, 1535, 2186, 1669,\n",
       "            10, 1706, 1720, 2353, 1597, 2609,   12,   37, 1917, 1814, 3858, 2039,\n",
       "          1957,   11, 1650, 2121, 1754, 1546, 2741, 1837, 1942, 1586, 2462,   51,\n",
       "          1913, 2155, 1549, 2186, 1907, 1549, 2483, 1565, 2256, 1858, 2534, 4415,\n",
       "            12,   37, 2368, 1604, 1607, 1527,   33,   40, 1621, 1536, 1546,   46,\n",
       "            39, 1802, 1700, 1656, 1549, 2811, 1996, 1546,   15,   12,   16, 2505,\n",
       "          1808, 2773, 3093,   12]),\n",
       "  tensor([  46, 1605, 1691, 1557, 3035, 1597, 1549, 2227,   33, 2185, 1596, 1576,\n",
       "          1532, 1706, 1542, 1738, 1546, 4176, 1549, 1611, 2510, 1528, 1597, 4787,\n",
       "          2962, 1539, 1715,   12, 4787, 2962, 3212, 1542,   33, 2456, 1543,   50,\n",
       "          2659, 1529, 1799, 2962, 3212,   10, 1549, 1535, 2188, 1546, 4176, 2307,\n",
       "          1542, 3902, 1525, 3545, 1675, 2185,   12,   37, 2750, 3545, 1675, 2185,\n",
       "          1834, 1552,   33, 1841, 3567, 4654, 1549, 4348,   51, 1661, 4654,   10,\n",
       "          1535, 2185, 1596, 1576, 1532, 3989, 1546, 1860,   33, 2241, 1554,   48,\n",
       "          1527, 4787, 2962, 1539, 1715, 1525, 1995, 1670, 2053, 1546, 4083, 1556,\n",
       "          2695, 4348,   51, 1661, 4654, 1546, 1663, 4283, 1935, 1878, 1546, 2758,\n",
       "          4143, 1682,   11, 3623, 1646, 1756, 4589,   12]),\n",
       "  tensor([1578, 1528, 1630, 2547, 1720, 1860, 1913, 4462, 1752, 1549, 2388, 1534,\n",
       "          3329, 1628,   12, 1542, 1743, 3627, 1538, 1845, 1810, 3272, 1542, 3743,\n",
       "          1859, 1543, 1535, 3080, 3166, 1525, 2066,   12,   37, 3206, 1586, 2388,\n",
       "          1534, 2201, 2686, 3081, 1580, 3743, 1525, 1913, 1726, 1549, 1962, 2342,\n",
       "            10, 1706, 3035, 1988, 1931, 2129, 1525,   33, 2392,   12,   37, 1917,\n",
       "          4829, 1546, 2138, 1667,   11, 2226, 3157, 2047, 1586, 4139, 2909, 2388,\n",
       "          1534, 2201, 2686, 1543, 3876,   51,   10, 1549, 1557, 2545, 2307, 1546,\n",
       "          1529, 2267, 1751, 1748, 2392,   12,   37, 1878, 1865,   33, 1901, 2129,\n",
       "          1543, 1535, 2388, 1534, 2201, 2686, 2636, 1658, 1535, 1858, 4829,   12,\n",
       "          1731, 1755, 3206, 1586, 2388, 1534, 2201, 2686, 2927, 1631,   33, 1560,\n",
       "          1530, 4773,   12,   37, 1878, 2226, 2140, 2949, 1586, 2542, 3630, 2307,\n",
       "          1655, 1931, 4462, 1752, 4715, 3559,   12]),\n",
       "  tensor([  46, 1910, 1630, 2367, 1860, 2000, 2867, 1546, 1580, 4746, 1554, 1800,\n",
       "          1525, 1910, 1772, 2694,   25, 2172,   10, 1931, 2476, 1525, 2277, 2694,\n",
       "          1866, 2000, 2668, 1526, 1533, 2577, 1568, 4351,   12,   46, 1605, 1691,\n",
       "            10, 1557, 1712, 1586, 2367, 1720, 2270, 3804, 2325, 3865, 1546, 1535,\n",
       "          2021, 1543, 2277, 3112,   12,   46, 1810, 1822, 1854, 1754, 1543, 3112,\n",
       "            10, 1557, 1530, 3526, 1760,   52, 1525, 2013, 3368, 3859, 1808, 1535,\n",
       "          3122, 1608, 1789, 1891, 1597,   33, 4079, 3859, 1808, 1630, 2367, 1549,\n",
       "          4543, 3604, 2549, 1525,   37, 3413, 1907,   12,   37, 1878, 3370, 1535,\n",
       "          3274, 1543, 2386, 2638, 3333, 2187, 4838, 1630, 2367, 1527, 4861, 3112,\n",
       "          1755,   12]),\n",
       "  tensor([  48, 1559, 1623, 1540, 1546, 4271, 1535, 2309, 1723, 1641, 1543, 4606,\n",
       "          1684, 1549, 3933, 1525, 3551, 1647, 3569, 1546, 2875, 1527, 3891, 1543,\n",
       "          2370, 1532, 1842, 1553, 4718, 1549, 4199,   12,   37, 1530,   10,   33,\n",
       "          1692, 1553, 2833,   11, 2138, 4402, 1538,   33, 2932, 1543, 2370, 1532,\n",
       "          1842, 1704, 2714, 2499, 1542, 3232, 1549, 2830,   12,   52, 1542, 2867,\n",
       "          1586, 2489, 3542, 1553, 2117, 1768, 3050, 1546, 1931, 1559, 2379, 1641,\n",
       "          1546, 2468, 2067, 1544, 1759,   51, 1543, 3724, 1971, 3959, 1842, 1542,\n",
       "          1840, 4178, 2009, 2489, 2307, 3050, 1546, 1559, 2379, 1641, 1546, 2051,\n",
       "          3083, 3959, 1630,   12]),\n",
       "  tensor([1532, 1778,    6,    7, 1542,   33, 3080, 1975,   11, 2537,   46,   39,\n",
       "          1802, 2131, 2339,   12, 2167, 1538, 2131, 3265, 1546, 1931, 3020, 1866,\n",
       "          2000, 1559, 1877, 2548, 1553, 2244, 1978,   12,   47, 2171,   10, 2884,\n",
       "          1613, 4991, 1767, 1608, 3535, 1546, 1931, 3020,   12,   37, 2434,   33,\n",
       "          2095, 1910, 1772, 1607, 1553, 3428, 2131, 3265, 1546, 3020,   10, 1704,\n",
       "          2355, 1962, 1800, 1549, 2634, 4806, 1724, 1618,   48, 2822,   12,   37,\n",
       "          2368, 1535, 2072, 1525, 1913, 1525,   11, 1837, 1549, 1807, 2771, 4423,\n",
       "            12,   46, 1913, 3272,   10, 1557, 1793, 1535, 2821, 4093, 1615, 2815,\n",
       "          1807, 1554, 1870, 1659,   12, 1533, 1525, 1837,    6, 3811, 1527, 1615,\n",
       "          2815, 1659,    7,   10, 1557, 2563, 4967,   12,   23,    4, 2059,   10,\n",
       "            17,   19,   12,   15,    4, 2343, 3464,    6,    7, 1808,   33, 2773,\n",
       "          2297,   12, 1533, 2771,   10, 1557, 2124, 1527, 1535, 1807, 1549, 2563,\n",
       "            21,   16,   12,   18,    4, 2059, 1608, 3065,   12,   21,    4,   12,\n",
       "            40, 1542, 1542, 1535, 1984, 1975,   11, 2537, 2087, 1547, 1608, 1824,\n",
       "          2498, 1553, 1605, 1656,   12]),\n",
       "  tensor([  46, 1605, 1691,   10, 1557, 2227, 1535, 2992, 1543,   33, 1811, 1772,\n",
       "          2090, 1586, 3564, 1962, 1758, 1525, 1535, 2259, 1543, 3226, 2342, 1549,\n",
       "          1662, 1535, 2314, 1898, 1543, 1811, 1772, 1525, 2919,   33, 2095, 2321,\n",
       "          3157, 3420,   12, 1527, 2197, 2804, 3571,    6,    7,   10, 1542, 1857,\n",
       "          1554, 1535, 3618, 1543, 1605, 2090,   12,   37, 2682, 1529, 3684, 1546,\n",
       "          2463, 1535, 3349, 1793, 1543, 1962, 1758,   10, 2504, 4694, 4254, 4412,\n",
       "            10, 1962, 3714,   51, 1549, 2321, 1560, 1528, 2016, 2028, 1605, 1811,\n",
       "          1772, 2090,   12, 1731, 2087, 1755, 1712, 1586, 1607, 1720, 2563, 2868,\n",
       "          2650, 1525, 2321, 2259, 2810, 2295, 1608, 2685, 2321, 3420,   12,   47,\n",
       "          2171,   10, 1608, 4378, 1546, 4092, 1538, 3094, 2095, 2342, 1553, 4807,\n",
       "          2339, 3701, 1887,   10, 1607, 4190,   51, 1546, 1712, 2868, 1848,   10,\n",
       "          2810, 2295, 1608, 2685, 2321, 3420, 2053, 1546, 2791, 2095, 2342, 1525,\n",
       "          3811, 1807,   12, 3158, 2718,   10, 1605, 2799, 4310, 1586, 1840, 1726,\n",
       "          1758, 2542, 1580, 4288, 1546, 3668,   33, 1630, 1546, 1580,   33, 2095,\n",
       "          2321, 2988,   33, 2086, 1584,   41, 3073,   12]),\n",
       "  tensor([  40, 1542, 2728, 1691, 1530, 3795, 1535, 1771, 1800, 1543,   10, 4506,\n",
       "            15,   10, 1706, 2018, 2088, 2566, 3119, 1658, 4409, 2958, 1724, 2094,\n",
       "          4542, 3139, 1715, 1533, 2921, 1710,   12,   40, 1542, 1755, 1655, 1532,\n",
       "            39, 3751, 1555, 2829, 4311, 1543, 4409, 2958, 1724, 1525, 2386, 1625,\n",
       "          1529, 1926,   12])],\n",
       " 'year': tensor([13,  4, 14, 14, 13, 13, 16, 10, 15, 11, 17, 18, 12, 16,  2, 16, 13,  9,\n",
       "          7, 17, 12, 13, 14, 10, 18, 15, 15,  8, 10, 12]),\n",
       " 'venue': tensor([305, 176, 186,   0,  13,  10,   0,  10,   0,   5,  17, 465, 221,  97,\n",
       "           9,   4,   9,  10, 129,  59,  48,   0,   0,  68, 213,  10, 185,   4,\n",
       "          27,  11]),\n",
       " 'coauthors': [tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 1]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       "  tensor([0, 0, 0,  ..., 0, 0, 0])],\n",
       " 'target': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 1243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(train_dataloader))\n",
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1375,
   "id": "860c9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.weights = torch.FloatTensor(keyword_list)\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.weights)\n",
    "        self.embedding.requires_grad = False\n",
    "        self.embedding = nn.Embedding(n_text+1, embed_dim)\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 100)\n",
    "        self.activation=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        #self.fc = nn.Linear(hidden_dim, 100)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, _input):\n",
    "        titles = _input['title']\n",
    "        word2vec_title_list = []\n",
    "        for curr_title in titles:\n",
    "            title_vec = self.embedding(curr_title)\n",
    "            word2vec_title_list.append(title_vec.mean(dim = 0))\n",
    "        embed_title = torch.stack(word2vec_title_list)\n",
    "        \n",
    "        #out = embed_title.reshape([embed_title.shape[0],1,embed_title.shape[1]])\n",
    "        \n",
    "        \n",
    "        #embed_abstract_list = []\n",
    "        #for curr_abstract in x['abstract']:\n",
    "        #    embed_abstract_list.append(curr_abstract.mean(dim = 0))\n",
    "        #embed_abstract = torch.stack(embed_abstract_list) # torch.Size([4, 100])\n",
    "        #print(pad_sequence(x['title']).size())\n",
    "        #print(pad_sequence(x['abstract']).size())\n",
    "        #out = pad_sequence(_input['abstract'], batch_first=True)\n",
    "        #print(out.size())\n",
    "        #out = torch.cat((pad_sequence(x['title']), pad_sequence(x['abstract'])), dim = 0)\n",
    "        #print(out)\n",
    "        \n",
    "        #h0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        #c0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        #out, (hn, cn) = self.lstm(out, (h0, c0))  \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #out = self.fc(out[:, -1, :]) \n",
    "        #out = self.sigmoid(out)\n",
    "        #return out\n",
    "        logits=self.linear1(embed_title)\n",
    "        logits=self.activation(logits)\n",
    "        logits=self.linear2(logits)\n",
    "        return torch.sigmoid(logits)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1376,
   "id": "05ebbf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4890, 0.5169, 0.4915,  ..., 0.4882, 0.4822, 0.5028],\n",
      "        [0.4916, 0.4923, 0.4801,  ..., 0.4959, 0.4880, 0.5216],\n",
      "        [0.4870, 0.5124, 0.4775,  ..., 0.5071, 0.4845, 0.5134],\n",
      "        ...,\n",
      "        [0.4995, 0.5160, 0.4823,  ..., 0.5054, 0.4682, 0.4920],\n",
      "        [0.4812, 0.5224, 0.4648,  ..., 0.4827, 0.4834, 0.4872],\n",
      "        [0.5005, 0.5284, 0.4758,  ..., 0.5057, 0.5050, 0.5013]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 1, 0, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 1376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LSTM(64, 64, 128, 1)\n",
    "print(clf(dataiter))\n",
    "predictions = np.where(clf(dataiter).detach().numpy()>=0.5, 1, 0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1377,
   "id": "50b1fb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100, loss = 0.0272, training f1 score = 0.6087\n",
      "epoch 2 / 100, loss = 0.0197, training f1 score = 0.7391\n",
      "epoch 3 / 100, loss = 0.0185, training f1 score = 0.8261\n",
      "epoch 4 / 100, loss = 0.0342, training f1 score = 0.6522\n",
      "epoch 5 / 100, loss = 0.0252, training f1 score = 0.6522\n",
      "epoch 6 / 100, loss = 0.0159, training f1 score = 0.8261\n",
      "epoch 7 / 100, loss = 0.0176, training f1 score = 0.8696\n",
      "epoch 8 / 100, loss = 0.0360, training f1 score = 0.6087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/352945707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#batch = batch.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/2852758823.py\u001b[0m in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'venue'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'venue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coauthors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coauthors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(),lr=0.1)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        #batch = batch.to(device)\n",
    "\n",
    "        # forward\n",
    "        #print(batch)\n",
    "        outputs = clf(batch)\n",
    "        \n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        #print(outputs.detach().numpy())\n",
    "        #break\n",
    "        f1_acc = f1_score(batch['target'].detach().numpy(), predictions, average=\"samples\", zero_division=1)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if (i + 1) % 1000 == 0:\n",
    "    print(f'epoch {epoch + 1} / {num_epochs}, loss = {loss.item():.4f}, training f1 score = {f1_acc:.4f}')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "1a579e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        outputs = clf(batch)\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>0.5, 1, 0)\n",
    "        test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "de78fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 1379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[20][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "id": "6dee4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, num):\n",
    "    result = []\n",
    "    for i, x in enumerate(lst):\n",
    "        if x==num:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "id": "f65af5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/26654980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mfinal_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "NN_result = test_df[['identifier']]\n",
    "NN_result.loc[:,'Predict'] = ''\n",
    "final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(batch_size):\n",
    "        final_result.append(test_preds[i][j])\n",
    "print(len(final_result))\n",
    "for i in range(len(final_result)):\n",
    "    result = final_result[i]\n",
    "    if len(find(list(result), 1)) == 0:\n",
    "        NN_result.loc[i,'Predict'] = -1\n",
    "    else:\n",
    "        NN_result.loc[i,'Predict'] = ' '.join(str(e) for e in find(list(result), 1))\n",
    "        \n",
    "NN_result = NN_result.rename(columns={'identifier':'ID'})\n",
    "NN_result.to_csv('./NN_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "318970df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier Predict\n",
       "0             0        \n",
       "1             1        \n",
       "2             2        \n",
       "3             3        \n",
       "4             4        \n",
       "..          ...     ...\n",
       "795         795        \n",
       "796         796        \n",
       "797         797        \n",
       "798         798        \n",
       "799         799        \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d34e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
