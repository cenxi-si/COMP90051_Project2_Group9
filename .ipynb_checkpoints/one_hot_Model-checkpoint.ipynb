{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a06f22",
   "metadata": {},
   "source": [
    "# Alternative Approaches\n",
    "This notebook is for other possible combinations of one-hot encoding. For example, coauthor+title, coauthor+abstract, or coauthor+title+abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fedcc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e763c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prolific = 99\n",
    "n_text = 4999\n",
    "n_authors = 21245\n",
    "n_prolific = 100\n",
    "n_years = 19\n",
    "n_venues = 464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5d366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train json file\n",
    "train_filename = './data/train.json'\n",
    "with open(train_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "test_filename = './data/test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# get a copy\n",
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "# extract coauthors as a new key from train.json\n",
    "for i in range(len(train)):\n",
    "    coauthors = []\n",
    "    prolific_authors = []\n",
    "    for auth in train[i]['authors']:\n",
    "        if auth >= max_prolific:\n",
    "            coauthors.append(auth)\n",
    "        else:\n",
    "            prolific_authors.append(auth)\n",
    "    train[i]['coauthors'] = coauthors\n",
    "    #if len(prolific_authors) == 0:\n",
    "        #prolific_authors.append(-1)\n",
    "    train[i]['prolific_authors'] = prolific_authors\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "train_df = train_df.drop(['authors'], axis=1)\n",
    "test_df = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a652a73",
   "metadata": {},
   "source": [
    "## Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4897397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e6c9a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "hidden_dim = 200\n",
    "output_dim = 101\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "22a09829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_torch(df, have_prolific):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # abstract and title\n",
    "        abstract_list = [0] * n_text\n",
    "        title_list = [0] * n_text\n",
    "        current_row = df.loc[i]\n",
    "        abstract_freq = collections.Counter(current_row['abstract'])\n",
    "        title_freq = collections.Counter(current_row['title'])\n",
    "        for key, value in dict(abstract_freq).items():\n",
    "            abstract_list[key-1] = value\n",
    "        for key, value in dict(title_freq).items():\n",
    "            title_list[key-1] = value\n",
    "        # year\n",
    "        year_list = [0] * n_years\n",
    "        year_list[current_row['year']-1] = 1\n",
    "        # venue\n",
    "        venue_list = [0] * (n_venues + 2) # 466 elements with the last element for empty venue\n",
    "        if current_row['venue'] == '':\n",
    "            venue_list[-1] = 1\n",
    "        else:\n",
    "            venue_list[current_row['venue']] = 1\n",
    "        # coauthors\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if current_row['coauthors'] == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in current_row['coauthors']:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "           \n",
    "        combined_features = coauthor_list + title_list\n",
    "        features.append(np.array(combined_features))\n",
    "        \n",
    "        if have_prolific == True:\n",
    "            # prolific authors\n",
    "            prolific_list = [0] * (n_prolific + 1) # 101 elements with the last element for empty coauthors\n",
    "            if current_row['prolific_authors'] == []:\n",
    "                prolific_list[-1] = 1\n",
    "            else:\n",
    "                for prolific in current_row['prolific_authors']:\n",
    "                    prolific_list[prolific] = 1\n",
    "            targets.append(np.array(prolific_list))\n",
    "    if have_prolific == True:\n",
    "        X_train = np.vstack(features)\n",
    "        y_train = np.array(targets)\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        X_test = np.vstack(features)\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "6177e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, istrain):\n",
    "        self.X = X\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.istrain == True:\n",
    "            return self.X[index], self.y[index]\n",
    "        else:\n",
    "            return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8af45b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = combine_features_torch(train_df, have_prolific=True)\n",
    "X_test = combine_features_torch(test_df, have_prolific=False)\n",
    "training_df = AuthorDataset(X_train, y_train, istrain = True)\n",
    "testing_df = AuthorDataset(X_test, y_train, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "39d3fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"x\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            output['x'] += [x]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"x\": []}\n",
    "        for data in batch:\n",
    "            output['x'] += [data]\n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "793f91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " 'target': tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "val_dataloader = DataLoader(dataset = validation_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(train_dataloader))\n",
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "295908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultilabelModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.Sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear2 = torch.nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.linear1(x)\n",
    "        output = self.linear2(output)\n",
    "        output = self.Sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "17351c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5190, 0.5173, 0.4898,  ..., 0.5142, 0.4920, 0.4915],\n",
      "        [0.5186, 0.5184, 0.4919,  ..., 0.5156, 0.4920, 0.4909],\n",
      "        [0.5199, 0.5206, 0.4938,  ..., 0.5144, 0.4908, 0.4923],\n",
      "        ...,\n",
      "        [0.5196, 0.5190, 0.4886,  ..., 0.5163, 0.4912, 0.4900],\n",
      "        [0.5205, 0.5187, 0.4918,  ..., 0.5156, 0.4915, 0.4930],\n",
      "        [0.5201, 0.5189, 0.4915,  ..., 0.5164, 0.4920, 0.4912]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "clf = MultilabelModel(21147, output_dim)\n",
    "print(clf(dataiter['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "2cfb6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, 101)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = x.reshape([x.shape[0],1,x.shape[1]])\n",
    "        h0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, (hn, cn) = self.lstm(out, (h0, c0))  \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "e2ee89f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4947, 0.5058, 0.4799,  ..., 0.5136, 0.4823, 0.5107],\n",
      "        [0.4965, 0.5014, 0.4843,  ..., 0.5103, 0.4834, 0.5148],\n",
      "        [0.5087, 0.5022, 0.4805,  ..., 0.5095, 0.4829, 0.5174],\n",
      "        ...,\n",
      "        [0.4999, 0.5150, 0.4762,  ..., 0.5089, 0.4848, 0.5166],\n",
      "        [0.5069, 0.5051, 0.4810,  ..., 0.5079, 0.4850, 0.5123],\n",
      "        [0.4981, 0.5034, 0.4786,  ..., 0.5089, 0.4820, 0.5131]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "clf = LSTM(21147, 64, 128, 1)\n",
    "print(clf(dataiter['x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9f2b43a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100, loss = 0.0368, training f1 score = 0.5152\n",
      "epoch 2 / 100, loss = 0.0211, training f1 score = 0.7576\n",
      "epoch 3 / 100, loss = 0.0144, training f1 score = 0.8788\n",
      "epoch 4 / 100, loss = 0.0217, training f1 score = 0.6970\n",
      "epoch 5 / 100, loss = 0.0134, training f1 score = 0.7576\n",
      "epoch 6 / 100, loss = 0.0118, training f1 score = 0.7879\n",
      "epoch 7 / 100, loss = 0.0115, training f1 score = 0.8182\n",
      "epoch 8 / 100, loss = 0.0114, training f1 score = 0.7576\n",
      "epoch 9 / 100, loss = 0.0083, training f1 score = 0.8182\n",
      "epoch 10 / 100, loss = 0.0118, training f1 score = 0.8081\n",
      "epoch 11 / 100, loss = 0.0059, training f1 score = 0.8990\n",
      "epoch 12 / 100, loss = 0.0078, training f1 score = 0.8788\n",
      "epoch 13 / 100, loss = 0.0018, training f1 score = 0.9394\n",
      "epoch 14 / 100, loss = 0.0011, training f1 score = 0.9899\n",
      "epoch 15 / 100, loss = 0.0060, training f1 score = 0.9293\n",
      "epoch 16 / 100, loss = 0.0027, training f1 score = 0.9596\n",
      "epoch 17 / 100, loss = 0.0035, training f1 score = 0.9394\n",
      "epoch 18 / 100, loss = 0.0018, training f1 score = 0.9697\n",
      "epoch 19 / 100, loss = 0.0060, training f1 score = 0.8889\n",
      "epoch 20 / 100, loss = 0.0013, training f1 score = 0.9899\n",
      "epoch 21 / 100, loss = 0.0031, training f1 score = 0.9535\n",
      "epoch 22 / 100, loss = 0.0030, training f1 score = 0.9293\n",
      "epoch 23 / 100, loss = 0.0028, training f1 score = 0.9394\n",
      "epoch 24 / 100, loss = 0.0029, training f1 score = 0.9394\n",
      "epoch 25 / 100, loss = 0.0031, training f1 score = 0.9596\n",
      "epoch 26 / 100, loss = 0.0030, training f1 score = 0.9697\n",
      "epoch 27 / 100, loss = 0.0027, training f1 score = 0.9394\n",
      "epoch 28 / 100, loss = 0.0035, training f1 score = 0.9091\n",
      "epoch 29 / 100, loss = 0.0029, training f1 score = 0.9192\n",
      "epoch 30 / 100, loss = 0.0017, training f1 score = 0.9596\n",
      "epoch 31 / 100, loss = 0.0018, training f1 score = 0.9697\n",
      "epoch 32 / 100, loss = 0.0022, training f1 score = 0.9293\n",
      "epoch 33 / 100, loss = 0.0070, training f1 score = 0.8727\n",
      "epoch 34 / 100, loss = 0.0078, training f1 score = 0.8788\n",
      "epoch 35 / 100, loss = 0.0021, training f1 score = 0.9798\n",
      "epoch 36 / 100, loss = 0.0006, training f1 score = 0.9697\n",
      "epoch 37 / 100, loss = 0.0020, training f1 score = 0.9394\n",
      "epoch 38 / 100, loss = 0.0019, training f1 score = 0.9394\n",
      "epoch 39 / 100, loss = 0.0031, training f1 score = 0.9293\n",
      "epoch 40 / 100, loss = 0.0014, training f1 score = 0.9697\n",
      "epoch 41 / 100, loss = 0.0015, training f1 score = 0.9697\n",
      "epoch 42 / 100, loss = 0.0029, training f1 score = 0.9596\n",
      "epoch 43 / 100, loss = 0.0019, training f1 score = 0.9394\n",
      "epoch 44 / 100, loss = 0.0031, training f1 score = 0.9394\n",
      "epoch 45 / 100, loss = 0.0054, training f1 score = 0.8788\n",
      "epoch 46 / 100, loss = 0.0008, training f1 score = 0.9697\n",
      "epoch 47 / 100, loss = 0.0008, training f1 score = 1.0000\n",
      "epoch 48 / 100, loss = 0.0010, training f1 score = 0.9899\n",
      "epoch 49 / 100, loss = 0.0009, training f1 score = 0.9697\n",
      "epoch 50 / 100, loss = 0.0038, training f1 score = 0.9091\n",
      "epoch 51 / 100, loss = 0.0022, training f1 score = 0.9293\n",
      "epoch 52 / 100, loss = 0.0034, training f1 score = 0.9394\n",
      "epoch 53 / 100, loss = 0.0022, training f1 score = 0.9495\n",
      "epoch 54 / 100, loss = 0.0012, training f1 score = 0.9697\n",
      "epoch 55 / 100, loss = 0.0010, training f1 score = 1.0000\n",
      "epoch 56 / 100, loss = 0.0033, training f1 score = 0.9697\n",
      "epoch 57 / 100, loss = 0.0009, training f1 score = 0.9697\n",
      "epoch 58 / 100, loss = 0.0024, training f1 score = 0.9394\n",
      "epoch 59 / 100, loss = 0.0031, training f1 score = 0.9293\n",
      "epoch 60 / 100, loss = 0.0046, training f1 score = 0.8586\n",
      "epoch 61 / 100, loss = 0.0043, training f1 score = 0.8788\n",
      "epoch 62 / 100, loss = 0.0007, training f1 score = 1.0000\n",
      "epoch 63 / 100, loss = 0.0039, training f1 score = 0.8788\n",
      "epoch 64 / 100, loss = 0.0020, training f1 score = 0.9394\n",
      "epoch 65 / 100, loss = 0.0026, training f1 score = 0.9697\n",
      "epoch 66 / 100, loss = 0.0022, training f1 score = 0.9596\n",
      "epoch 67 / 100, loss = 0.0027, training f1 score = 0.9596\n",
      "epoch 68 / 100, loss = 0.0003, training f1 score = 1.0000\n",
      "epoch 69 / 100, loss = 0.0007, training f1 score = 0.9697\n",
      "epoch 70 / 100, loss = 0.0015, training f1 score = 0.9596\n",
      "epoch 71 / 100, loss = 0.0056, training f1 score = 0.8889\n",
      "epoch 72 / 100, loss = 0.0051, training f1 score = 0.9091\n",
      "epoch 73 / 100, loss = 0.0034, training f1 score = 0.9091\n",
      "epoch 74 / 100, loss = 0.0045, training f1 score = 0.9394\n",
      "epoch 75 / 100, loss = 0.0034, training f1 score = 0.8990\n",
      "epoch 76 / 100, loss = 0.0044, training f1 score = 0.9394\n",
      "epoch 77 / 100, loss = 0.0007, training f1 score = 1.0000\n",
      "epoch 78 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 79 / 100, loss = 0.0011, training f1 score = 0.9697\n",
      "epoch 80 / 100, loss = 0.0036, training f1 score = 0.9091\n",
      "epoch 81 / 100, loss = 0.0001, training f1 score = 1.0000\n",
      "epoch 82 / 100, loss = 0.0035, training f1 score = 0.9091\n",
      "epoch 83 / 100, loss = 0.0003, training f1 score = 1.0000\n",
      "epoch 84 / 100, loss = 0.0034, training f1 score = 0.9394\n",
      "epoch 85 / 100, loss = 0.0022, training f1 score = 0.9697\n",
      "epoch 86 / 100, loss = 0.0029, training f1 score = 0.9091\n",
      "epoch 87 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 88 / 100, loss = 0.0023, training f1 score = 0.9697\n",
      "epoch 89 / 100, loss = 0.0009, training f1 score = 0.9899\n",
      "epoch 90 / 100, loss = 0.0050, training f1 score = 0.9091\n",
      "epoch 91 / 100, loss = 0.0034, training f1 score = 0.9596\n",
      "epoch 92 / 100, loss = 0.0010, training f1 score = 0.9697\n",
      "epoch 93 / 100, loss = 0.0036, training f1 score = 0.8990\n",
      "epoch 94 / 100, loss = 0.0056, training f1 score = 0.8990\n",
      "epoch 95 / 100, loss = 0.0022, training f1 score = 0.9293\n",
      "epoch 96 / 100, loss = 0.0014, training f1 score = 0.9545\n",
      "epoch 97 / 100, loss = 0.0035, training f1 score = 0.9242\n",
      "epoch 98 / 100, loss = 0.0027, training f1 score = 0.9697\n",
      "epoch 99 / 100, loss = 0.0002, training f1 score = 1.0000\n",
      "epoch 100 / 100, loss = 0.0007, training f1 score = 0.9697\n"
     ]
    }
   ],
   "source": [
    "# loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(),lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        #batch = batch.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = clf(batch['x'])\n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        f1_acc = f1_score(batch['target'].detach().numpy(), predictions, average=\"samples\", zero_division=1)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if (i + 1) % 100 == 0:\n",
    "    print(f'epoch {epoch + 1} / {num_epochs}, loss = {loss.item():.4f}, training f1 score = {f1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b4d3c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        outputs = clf(batch['x'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fe9b940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds[1][39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cc4c1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, num):\n",
    "    result = []\n",
    "    for i, x in enumerate(lst):\n",
    "        if x==num:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8b2cb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(4):\n",
    "        test_final_result.append(test_preds[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ebae9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "NN_result = test_df[['identifier']]\n",
    "NN_result.loc[:,'Predict'] = ''\n",
    "final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(batch_size):\n",
    "        final_result.append(test_preds[i][j])\n",
    "print(len(final_result))\n",
    "for i in range(len(final_result)):\n",
    "    result = final_result[i]\n",
    "    if result[-1] == 1 or len(find(list(result), 1)) == 0:\n",
    "        NN_result.loc[i,'Predict'] = -1\n",
    "    else:\n",
    "        NN_result.loc[i,'Predict'] = ' '.join(str(e) for e in find(list(result), 1))\n",
    "        \n",
    "NN_result = NN_result.rename(columns={'identifier':'ID'})\n",
    "NN_result.to_csv('./NN_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "80cd5bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>13 71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Predict\n",
       "0      0      92\n",
       "1      1      -1\n",
       "2      2      31\n",
       "3      3      -1\n",
       "4      4      -1\n",
       "..   ...     ...\n",
       "795  795      54\n",
       "796  796      97\n",
       "797  797   13 71\n",
       "798  798      71\n",
       "799  799      -1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf63636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
