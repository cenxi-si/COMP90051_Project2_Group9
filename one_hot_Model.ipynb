{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fedcc002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e763c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prolific = 99\n",
    "n_text = 4999\n",
    "n_authors = 21245\n",
    "n_prolific = 100\n",
    "n_years = 19\n",
    "n_venues = 464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5d366b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train json file\n",
    "train_filename = './data/train.json'\n",
    "with open(train_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "test_filename = './data/test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# get a copy\n",
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "# extract coauthors as a new key from train.json\n",
    "for i in range(len(train)):\n",
    "    coauthors = []\n",
    "    prolific_authors = []\n",
    "    for auth in train[i]['authors']:\n",
    "        if auth >= max_prolific:\n",
    "            coauthors.append(auth)\n",
    "        else:\n",
    "            prolific_authors.append(auth)\n",
    "    train[i]['coauthors'] = coauthors\n",
    "    #if len(prolific_authors) == 0:\n",
    "        #prolific_authors.append(-1)\n",
    "    train[i]['prolific_authors'] = prolific_authors\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "train_df = train_df.drop(['authors'], axis=1)\n",
    "test_df = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "639b48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df, have_prolific):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # abstract and title\n",
    "        abstract_list = [0] * n_text\n",
    "        title_list = [0] * n_text\n",
    "        current_row = df.loc[i]\n",
    "        abstract_freq = collections.Counter(current_row['abstract'])\n",
    "        title_freq = collections.Counter(current_row['title'])\n",
    "        for key, value in dict(abstract_freq).items():\n",
    "            abstract_list[key-1] = value\n",
    "        for key, value in dict(title_freq).items():\n",
    "            title_list[key-1] = value\n",
    "        # year\n",
    "        year_list = [0] * n_years\n",
    "        year_list[current_row['year']-1] = 1\n",
    "        # venue\n",
    "        venue_list = [0] * (n_venues + 2) # 466 elements with the last element for empty venue\n",
    "        if current_row['venue'] == '':\n",
    "            venue_list[-1] = 1\n",
    "        else:\n",
    "            venue_list[current_row['venue']] = 1\n",
    "        # coauthors\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if current_row['coauthors'] == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in current_row['coauthors']:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "           \n",
    "        combined_features = abstract_list + title_list + year_list + venue_list + coauthor_list\n",
    "        features.append(np.array(combined_features))\n",
    "        \n",
    "        if have_prolific == True:\n",
    "            # prolific authors\n",
    "            prolific_list = [0] * (n_prolific + 1) # 101 elements with the last element for empty coauthors\n",
    "            if current_row['prolific_authors'] == []:\n",
    "                prolific_list[-1] = 1\n",
    "            else:\n",
    "                for prolific in current_row['prolific_authors']:\n",
    "                    prolific_list[prolific] = 1\n",
    "            targets.append(np.array(prolific_list))\n",
    "    if have_prolific == True:\n",
    "        X_train = np.vstack(features)\n",
    "        y_train = np.array(targets)\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        X_test = np.vstack(features)\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "18b080df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25793, 31630)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = combine_features(train_df, have_prolific=True)\n",
    "X_test = combine_features(test_df, have_prolific=False)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ba59b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.24, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d593f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass n_neighbors=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score under MLKNN classifier is:0.6542169508733876\n"
     ]
    }
   ],
   "source": [
    "mlknn_clf = MLkNN(k = 10, s = 0.3)\n",
    "\n",
    "# train\n",
    "mlknn_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "mlknn_pred = mlknn_clf.predict(X_val)\n",
    "mlknn_acc = f1_score(mlknn_pred, y_val, average = \"samples\")\n",
    "print(f\"f1 score under MLKNN classifier is:{mlknn_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9149b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "mlknn_pred_test = mlknn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af03e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, num):\n",
    "    result = []\n",
    "    for i, x in enumerate(lst):\n",
    "        if x==num:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "715ef648",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "mlknn_result = test_df[['identifier']]\n",
    "mlknn_result.loc[:,'Predict'] = ''\n",
    "\n",
    "for i in range(len(mlknn_pred_test.toarray())):\n",
    "    result = mlknn_pred_test.toarray()[i]\n",
    "    if result[-1] == 1 or len(find(list(result), 1)) == 0:\n",
    "        mlknn_result.loc[i,'Predict'] = -1\n",
    "    else:\n",
    "        mlknn_result.loc[i,'Predict'] = ' '.join(str(e) for e in find(list(result), 1))\n",
    "        \n",
    "mlknn_result = mlknn_result.rename(columns={'identifier':'ID'})\n",
    "mlknn_result.to_csv('./results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5dd28ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Predict\n",
       "0      0      -1\n",
       "1      1      -1\n",
       "2      2      -1\n",
       "3      3      -1\n",
       "4      4      -1\n",
       "..   ...     ...\n",
       "795  795      -1\n",
       "796  796      -1\n",
       "797  797      -1\n",
       "798  798      -1\n",
       "799  799      43\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlknn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a652a73",
   "metadata": {},
   "source": [
    "## Nerual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4897397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e6c9a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "hidden_dim = 200\n",
    "output_dim = 101\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "935001c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_torch(df, have_prolific):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # abstract and title\n",
    "        abstract_list = [0] * n_text\n",
    "        title_list = [0] * n_text\n",
    "        current_row = df.loc[i]\n",
    "        abstract_freq = collections.Counter(current_row['abstract'])\n",
    "        title_freq = collections.Counter(current_row['title'])\n",
    "        for key, value in dict(abstract_freq).items():\n",
    "            abstract_list[key-1] = value\n",
    "        for key, value in dict(title_freq).items():\n",
    "            title_list[key-1] = value\n",
    "        # year\n",
    "        year_list = [0] * n_years\n",
    "        year_list[current_row['year']-1] = 1\n",
    "        # venue\n",
    "        venue_list = [0] * (n_venues + 2) # 466 elements with the last element for empty venue\n",
    "        if current_row['venue'] == '':\n",
    "            venue_list[-1] = 1\n",
    "        else:\n",
    "            venue_list[current_row['venue']] = 1\n",
    "        # coauthors\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if current_row['coauthors'] == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in current_row['coauthors']:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "           \n",
    "        combined_features = title_list + coauthor_list + abstract_list\n",
    "        features.append(np.array(combined_features))\n",
    "        \n",
    "        if have_prolific == True:\n",
    "            # prolific authors\n",
    "            prolific_list = [0] * (n_prolific + 1) # 101 elements with the last element for empty coauthors\n",
    "            if current_row['prolific_authors'] == []:\n",
    "                prolific_list[-1] = 1\n",
    "            else:\n",
    "                for prolific in current_row['prolific_authors']:\n",
    "                    prolific_list[prolific] = 1\n",
    "            targets.append(np.array(prolific_list))\n",
    "    if have_prolific == True:\n",
    "        X_train = np.vstack(features)\n",
    "        y_train = np.array(targets)\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        X_test = np.vstack(features)\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "6177e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, istrain):\n",
    "        self.X = X\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.istrain == True:\n",
    "            return self.X[index], self.y[index]\n",
    "        else:\n",
    "            return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8af45b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = combine_features_torch(train_df, have_prolific=True)\n",
    "X_test = combine_features_torch(test_df, have_prolific=False)\n",
    "training_df = AuthorDataset(X_train, y_train, istrain = True)\n",
    "#validation_df = AuthorDataset(X_val, y_val, istrain = False)\n",
    "testing_df = AuthorDataset(X_test, y_train, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "39d3fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"x\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            output['x'] += [x]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"x\": []}\n",
    "        for data in batch:\n",
    "            output['x'] += [data]\n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "793f91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "val_dataloader = DataLoader(dataset = validation_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(val_dataloader))\n",
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "295908e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultilabelModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_dim, 128)\n",
    "        self.Sigmoid = torch.nn.Sigmoid()\n",
    "        self.linear2 = torch.nn.Linear(128, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.linear1(x)\n",
    "        output = self.linear2(output)\n",
    "        output = self.Sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b43a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100, loss = 0.0331, training f1 score = 0.6364\n",
      "epoch 2 / 100, loss = 0.0126, training f1 score = 0.8081\n",
      "epoch 3 / 100, loss = 0.0126, training f1 score = 0.8485\n",
      "epoch 4 / 100, loss = 0.0050, training f1 score = 0.9596\n",
      "epoch 5 / 100, loss = 0.0016, training f1 score = 0.9596\n",
      "epoch 6 / 100, loss = 0.0036, training f1 score = 0.9495\n",
      "epoch 7 / 100, loss = 0.0030, training f1 score = 0.9293\n",
      "epoch 8 / 100, loss = 0.0025, training f1 score = 0.8990\n",
      "epoch 9 / 100, loss = 0.0032, training f1 score = 0.9232\n",
      "epoch 10 / 100, loss = 0.0019, training f1 score = 0.9697\n",
      "epoch 11 / 100, loss = 0.0015, training f1 score = 0.9899\n",
      "epoch 12 / 100, loss = 0.0024, training f1 score = 0.9293\n",
      "epoch 13 / 100, loss = 0.0009, training f1 score = 0.9596\n",
      "epoch 14 / 100, loss = 0.0007, training f1 score = 0.9697\n",
      "epoch 15 / 100, loss = 0.0006, training f1 score = 0.9697\n",
      "epoch 16 / 100, loss = 0.0009, training f1 score = 0.9798\n",
      "epoch 17 / 100, loss = 0.0008, training f1 score = 0.9899\n",
      "epoch 18 / 100, loss = 0.0004, training f1 score = 1.0000\n",
      "epoch 19 / 100, loss = 0.0006, training f1 score = 0.9899\n",
      "epoch 20 / 100, loss = 0.0004, training f1 score = 1.0000\n",
      "epoch 21 / 100, loss = 0.0002, training f1 score = 1.0000\n",
      "epoch 22 / 100, loss = 0.0009, training f1 score = 0.9697\n",
      "epoch 23 / 100, loss = 0.0011, training f1 score = 0.9394\n",
      "epoch 24 / 100, loss = 0.0006, training f1 score = 1.0000\n",
      "epoch 25 / 100, loss = 0.0022, training f1 score = 0.9293\n",
      "epoch 26 / 100, loss = 0.0065, training f1 score = 0.9939\n",
      "epoch 27 / 100, loss = 0.0011, training f1 score = 0.9899\n",
      "epoch 28 / 100, loss = 0.0012, training f1 score = 0.9697\n",
      "epoch 29 / 100, loss = 0.0004, training f1 score = 0.9899\n",
      "epoch 30 / 100, loss = 0.0004, training f1 score = 1.0000\n",
      "epoch 31 / 100, loss = 0.0001, training f1 score = 1.0000\n",
      "epoch 32 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 33 / 100, loss = 0.0012, training f1 score = 0.9091\n",
      "epoch 34 / 100, loss = 0.0010, training f1 score = 0.9394\n",
      "epoch 35 / 100, loss = 0.0006, training f1 score = 0.9697\n",
      "epoch 36 / 100, loss = 0.0001, training f1 score = 1.0000\n",
      "epoch 37 / 100, loss = 0.0008, training f1 score = 0.9899\n",
      "epoch 38 / 100, loss = 0.0002, training f1 score = 1.0000\n",
      "epoch 39 / 100, loss = 0.0008, training f1 score = 0.9697\n",
      "epoch 40 / 100, loss = 0.0007, training f1 score = 0.9899\n",
      "epoch 41 / 100, loss = 0.0007, training f1 score = 0.9697\n",
      "epoch 42 / 100, loss = 0.0005, training f1 score = 0.9899\n",
      "epoch 43 / 100, loss = 0.0004, training f1 score = 1.0000\n",
      "epoch 44 / 100, loss = 0.0001, training f1 score = 1.0000\n",
      "epoch 45 / 100, loss = 0.0007, training f1 score = 0.9697\n",
      "epoch 46 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 47 / 100, loss = 0.0011, training f1 score = 0.9697\n",
      "epoch 48 / 100, loss = 0.0014, training f1 score = 0.9697\n",
      "epoch 49 / 100, loss = 0.0022, training f1 score = 0.9899\n",
      "epoch 50 / 100, loss = 0.0003, training f1 score = 0.9697\n",
      "epoch 51 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 52 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 53 / 100, loss = 0.0017, training f1 score = 0.9697\n",
      "epoch 54 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 55 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 56 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 57 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 58 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 59 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 60 / 100, loss = 0.0000, training f1 score = 1.0000\n",
      "epoch 61 / 100, loss = 0.0000, training f1 score = 1.0000\n"
     ]
    }
   ],
   "source": [
    "clf = MultilabelModel(31145, output_dim)\n",
    "# loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(),lr=learning_rate)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        #batch = batch.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = clf(batch['x'])\n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        #print(predictions)\n",
    "        #break\n",
    "        f1_acc = f1_score(batch['target'].detach().numpy(), predictions, average=\"samples\", zero_division=1)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if (i + 1) % 100 == 0:\n",
    "    print(f'epoch {epoch + 1} / {num_epochs}, loss = {loss.item():.4f}, training f1 score = {f1_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b4d3c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        outputs = clf(batch['x'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fe9b940c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8b2cb51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(4):\n",
    "        test_final_result.append(test_preds[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ebae9abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "NN_result = test_df[['identifier']]\n",
    "NN_result.loc[:,'Predict'] = ''\n",
    "final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(batch_size):\n",
    "        final_result.append(test_preds[i][j])\n",
    "print(len(final_result))\n",
    "for i in range(len(final_result)):\n",
    "    result = final_result[i]\n",
    "    if result[-1] == 1 or len(find(list(result), 1)) == 0:\n",
    "        NN_result.loc[i,'Predict'] = -1\n",
    "    else:\n",
    "        NN_result.loc[i,'Predict'] = ' '.join(str(e) for e in find(list(result), 1))\n",
    "        \n",
    "NN_result = NN_result.rename(columns={'identifier':'ID'})\n",
    "NN_result.to_csv('./NN_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "80cd5bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Predict\n",
       "0      0      -1\n",
       "1      1      -1\n",
       "2      2      -1\n",
       "3      3      23\n",
       "4      4      -1\n",
       "..   ...     ...\n",
       "795  795      -1\n",
       "796  796      97\n",
       "797  797      -1\n",
       "798  798      -1\n",
       "799  799      -1\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf63636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
