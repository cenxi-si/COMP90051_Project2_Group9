{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f76e368",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElmoModel \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\simple_elmo\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple_elmo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melmo_helpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ElmoModel, divide_chunks\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batcher\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BidirectionalLanguageModel\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\simple_elmo\\elmo_helpers.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batcher\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_elmo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01melmo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m weight_layers\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from simple_elmo import ElmoModel \n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_elmo_vectors(SENTENCES)\n",
    "model = ElmoModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train json file\n",
    "train_filename = 'train.json'\n",
    "with open(train_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "test_filename = 'test.json'\n",
    "with open(test_filename, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# get a copy\n",
    "train = raw_train.copy()\n",
    "test = raw_test.copy()\n",
    "\n",
    "# extract coauthors as a new key from train.json\n",
    "for i in train:\n",
    "    i['prolific_authors'] = [j for j in i['authors'] if j in range(100)]\n",
    "    i['coauthors'] = [j for j in i['authors'] if j not in range(100)]\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame.from_dict(train)\n",
    "train_df = train_df.drop(['authors'], axis=1)\n",
    "test_df = pd.DataFrame.from_dict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d40e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f798ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "# Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "hidden_dim = 200\n",
    "output_dim = 101\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c17c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train Set\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.05)\n",
    "length = train_df['prolific_authors'].str.len()\n",
    "# number of papers without any prolific author\n",
    "count_empty = (length == 0).sum()\n",
    "# number of papers with prolific authors\n",
    "count_non_emtpy = (length >0).sum()\n",
    "print(count_empty)\n",
    "print(count_non_emtpy)\n",
    "train_without = train_df[train_df['prolific_authors'].str.len() == 0]\n",
    "train_with = train_df[train_df['prolific_authors'].str.len() > 0]\n",
    "len(train_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52448f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_with, train_without.sample(len(train_with))])\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d85b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_torch(df, have_prolific):\n",
    "    features = []\n",
    "    targets = []\n",
    "    for i in range(df.shape[0]):\n",
    "        # abstract and title\n",
    "        abstract_list = [0] * n_text\n",
    "        title_list = [0] * n_text\n",
    "        current_row = df.loc[i]\n",
    "        abstract_freq = collections.Counter(current_row['abstract'])\n",
    "        title_freq = collections.Counter(current_row['title'])\n",
    "        for key, value in dict(abstract_freq).items():\n",
    "            abstract_list[key-1] = value\n",
    "        for key, value in dict(title_freq).items():\n",
    "            title_list[key-1] = value\n",
    "        # year\n",
    "        year_list = [0] * n_years\n",
    "        year_list[current_row['year']-1] = 1\n",
    "        # venue\n",
    "        venue_list = [0] * (n_venues + 2) # 466 elements with the last element for empty venue\n",
    "        if current_row['venue'] == '':\n",
    "            venue_list[-1] = 1\n",
    "        else:\n",
    "            venue_list[current_row['venue']] = 1\n",
    "        # coauthors\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if current_row['coauthors'] == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in current_row['coauthors']:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "           \n",
    "        combined_features = coauthor_list\n",
    "        features.append(np.array(combined_features))\n",
    "        \n",
    "        if have_prolific == True:\n",
    "            # prolific authors\n",
    "            prolific_list = [0] * (n_prolific + 1) # 101 elements with the last element for empty coauthors\n",
    "            if current_row['prolific_authors'] == []:\n",
    "                prolific_list[-1] = 1\n",
    "            else:\n",
    "                for prolific in current_row['prolific_authors']:\n",
    "                    prolific_list[prolific] = 1\n",
    "            targets.append(np.array(prolific_list))\n",
    "    if have_prolific == True:\n",
    "        X_train = np.vstack(features)\n",
    "        y_train = np.array(targets)\n",
    "        return X_train, y_train\n",
    "    else:\n",
    "        X_test = np.vstack(features)\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, istrain):\n",
    "        self.X = X\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.istrain == True:\n",
    "            return self.X[index], self.y[index]\n",
    "        else:\n",
    "            return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba239376",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = combine_features_torch(train_df, have_prolific=True)\n",
    "X_test = combine_features_torch(test_df, have_prolific=False)\n",
    "training_df = AuthorDataset(X_train, y_train, istrain = True)\n",
    "testing_df = AuthorDataset(X_test, y_train, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"x\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            output['x'] += [x]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"x\": []}\n",
    "        for data in batch:\n",
    "            output['x'] += [data]\n",
    "        output['x'] = torch.tensor(output['x'], dtype=torch.float)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "# val_dataloader = DataLoader(dataset = validation_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(train_dataloader))\n",
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElmoModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
