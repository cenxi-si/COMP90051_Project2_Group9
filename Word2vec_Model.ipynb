{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "86e90b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1390,
   "id": "a41e5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prolific = 99\n",
    "n_text = 4999\n",
    "n_authors = 21245\n",
    "n_prolific = 100\n",
    "n_coauthors = n_authors - n_prolific + 1\n",
    "n_years = 19\n",
    "n_venues = 466\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1dcc8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "835927d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25793, 6)"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = './data/train.json'\n",
    "test_data_path = './data/test.json'\n",
    "# read train json file\n",
    "with open(train_data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_train = json.load(f)\n",
    "# read test json file\n",
    "with open(test_data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_test = json.load(f)\n",
    "    \n",
    "# extract coauthors as a new key from train.json\n",
    "title_list = []\n",
    "abstract_list = []\n",
    "word_list = []\n",
    "for i in range(len(raw_train)):\n",
    "    coauthors = []\n",
    "    prolific_authors = []\n",
    "    for auth in raw_train[i]['authors']:\n",
    "        if auth >= max_prolific:\n",
    "            coauthors.append(auth)\n",
    "        else:\n",
    "            prolific_authors.append(auth)\n",
    "    if len(prolific_authors) == 0:\n",
    "        prolific_authors = -1\n",
    "    raw_train[i]['coauthors'] = coauthors\n",
    "    raw_train[i]['prolific_authors'] = prolific_authors\n",
    "    \n",
    "train_df = pd.DataFrame.from_dict(raw_train)\n",
    "train_df = train_df.drop(['authors'], axis=1)\n",
    "train_df['venue'] = train_df['venue'].replace('', 465)\n",
    "for i in range(len(train_df)):\n",
    "    title_list.append(train_df['title'][i])\n",
    "    abstract_list.append(train_df['abstract'][i])\n",
    "    word_list.append(train_df['title'][i])\n",
    "    word_list.append(train_df['abstract'][i])\n",
    "\n",
    "    \n",
    "test_df = pd.DataFrame.from_dict(raw_test)\n",
    "test_df['venue'] = test_df['venue'].replace('', 465)\n",
    "for i in range(len(test_df)):\n",
    "    title_list.append(test_df['title'][i])\n",
    "    abstract_list.append(test_df['abstract'][i])\n",
    "    word_list.append(test_df['title'][i])\n",
    "    word_list.append(test_df['abstract'][i])\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "id": "42b3bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3522, 2223, 1653], [2085, 1719, 1846, 1745, 2243, 1553, 1606, 1596, 42, 41, 1606, 1665, 40, 1615, 1677, 40, 127, 43, 140, 50, 1583, 43], [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 56, 1687, 1644, 1546, 46, 1624, 1547, 4226], [38, 1592, 2088, 1543, 1574, 1727, 1597, 1813, 1926, 1527, 1623, 1621, 50, 1620, 1632], [46, 1617, 1667, 3979, 2073, 37, 53, 2080, 1545, 40, 1804, 1530, 2587, 57, 4624], [34, 3646, 2073, 2035, 2346, 1886, 1543, 57, 1627, 11, 53, 1584, 1903, 3628, 1724], [1615, 1966, 11, 3495, 1656, 4345, 24, 2353, 1826, 2156, 3781, 4692], [3591, 4914, 46, 2421, 1608, 37, 1740, 1825, 1549, 57, 45, 2303, 1539, 2154, 51], [1560, 1694, 11, 1546, 11, 3066, 1728, 47, 1603, 1553, 11, 1546, 11, 1594, 1531, 1532, 1547], [1751, 44, 3474, 1854, 1872, 1538, 24, 2574, 52, 1918, 57, 1527, 46, 1528, 1727, 1525, 2149], [47, 1570, 40, 1733, 1735, 1540, 1525, 1535, 1540, 1863, 1543, 47, 1574, 1541, 1854, 1549, 2796, 1854, 53, 1540, 1537, 4454, 2062, 1538, 57, 1548, 3391], [1578, 1528, 11, 3716, 55, 47, 11, 1560, 1746, 1543, 50, 1620, 2388, 1547, 47, 1603], [37, 2375, 1568, 1910, 1772, 1543, 1534, 1588, 3632, 57], [3591, 37, 1596, 1567, 37, 1662, 1707, 1704, 1964, 1540, 2543, 1544, 1600, 1929, 1773, 1531, 4547, 1803, 1533, 1886], [47, 1574, 1541, 2812, 10, 3255, 1644, 1549, 1536, 1543, 1551, 1728, 1747, 1671, 1575, 44, 1813, 1587, 1780, 1553, 37, 55, 1529, 1589, 1629, 33, 1660, 51], [1542, 1723, 53, 1584, 2943, 1525, 47, 1945, 2014, 3207, 1545, 46, 1624, 1547, 56, 1687, 1644], [1731, 1578, 1528, 2973, 1561, 1551, 1547, 1554, 40, 4972], [46, 1910, 35, 1599, 1542, 2601, 1543, 1530, 4625, 1744, 3591, 1531, 1684], [47, 1574, 1541, 2812, 1543, 56, 3569, 1545, 1564, 1555, 1527, 47, 1603, 51, 1525, 37, 1766, 1549, 1540, 3267, 1553]]\n"
     ]
    }
   ],
   "source": [
    "print(title_list[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "id": "758c2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "titlemodel = Word2Vec(title_list, min_count=1, vector_size=128)\n",
    "input_size = 128\n",
    "word_vectors = titlemodel.wv\n",
    "keyword_list = []\n",
    "for i in range(len(train_df)):\n",
    "    title_i = title_list[i]\n",
    "    keyword_vec = np.zeros(input_size)\n",
    "    for word in title_i:\n",
    "        keyword_vec += word_vectors[word]\n",
    "    keyword_vec = keyword_vec/len(title_i)\n",
    "    keyword_list.append(keyword_vec)\n",
    "keyword_list = np.array(keyword_list)\n",
    "\n",
    "\n",
    "\n",
    "#wordmodel = Word2Vec(word_list, min_count=1)\n",
    "#wordmodel.save(\"word_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1383,
   "id": "799d1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstractmodel = Word2Vec(abstract_list, min_count=1, vector_size=128)\n",
    "input_size = 128\n",
    "word_vectors2 = abstractmodel.wv\n",
    "keyword_list2 = []\n",
    "for i in range(len(train_df)):\n",
    "    abstract_i = abstract_list[i]\n",
    "    keyword_vec = np.zeros(input_size)\n",
    "    for word in abstract_i:\n",
    "        keyword_vec += word_vectors2[word]\n",
    "    keyword_vec = keyword_vec/len(abstract_i)\n",
    "    keyword_list2.append(keyword_vec)\n",
    "keyword_list2 = np.array(keyword_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1384,
   "id": "607455bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.48349956 -0.51170217  0.11739261 ...  0.60842679 -0.13248341\n",
      "   0.71195911]\n",
      " [-0.42123375 -0.51167642  0.72696966 ... -0.17041562  0.27131101\n",
      "   0.20101655]\n",
      " [ 0.33492874 -0.41464009  0.30027379 ...  0.27510964 -0.09162126\n",
      "   0.18025668]\n",
      " ...\n",
      " [ 0.08501742 -0.39033312  0.44491885 ... -0.27592777  0.33888846\n",
      "   0.23611297]\n",
      " [-0.60112178 -0.60781407  0.48994653 ...  0.24793403  0.22349386\n",
      "   0.41398034]\n",
      " [ 0.08621521 -0.3738243   0.1974229  ...  0.33539617  0.09805431\n",
      "   0.30733421]]\n"
     ]
    }
   ],
   "source": [
    "keywords = keyword_list + keyword_list2\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "5a437f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>prolific_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>[2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...</td>\n",
       "      <td>20</td>\n",
       "      <td>[41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...</td>\n",
       "      <td>[13720]</td>\n",
       "      <td>[42, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>[40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...</td>\n",
       "      <td>[1359, 15881]</td>\n",
       "      <td>[45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>[46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...</td>\n",
       "      <td>4</td>\n",
       "      <td>[40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[97]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                           abstract  venue  \\\n",
       "0     9  [2455, 1858, 2335, 1543, 1800, 1860, 2000, 286...     20   \n",
       "1    15  [40, 1542, 1691, 2449, 1535, 3616, 2206, 1904,...      2   \n",
       "2    10  [46, 1624, 1547, 56, 1687, 1644, 6, 7, 3386, 1...      4   \n",
       "\n",
       "                                               title      coauthors  \\\n",
       "0  [41, 1550, 1563, 1594, 1544, 1919, 1644, 37, 1...        [13720]   \n",
       "1  [1731, 47, 11, 57, 4624, 1525, 1535, 47, 11, 3...  [1359, 15881]   \n",
       "2  [40, 1733, 1735, 1540, 1655, 46, 1624, 1547, 5...             []   \n",
       "\n",
       "  prolific_authors  \n",
       "0         [42, 36]  \n",
       "1             [45]  \n",
       "2             [97]  "
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_prolific = train_df[train_df['prolific_authors'] != -1]\n",
    "train_df_noprolific = train_df[train_df['prolific_authors'] == -1]\n",
    "train_df_combine = pd.concat([train_df_prolific, train_df_noprolific.tail(3000)], axis=0)\n",
    "train_df_combine = train_df_combine.reset_index(drop=True)\n",
    "train_df_combine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "7b1aedb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>coauthors</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "      <th>venue</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[16336, 1762, 4357, 12564]</td>\n",
       "      <td>19</td>\n",
       "      <td>[37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...</td>\n",
       "      <td>223</td>\n",
       "      <td>[3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[21189, 14088]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...</td>\n",
       "      <td>223</td>\n",
       "      <td>[40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3625, 1198, 19889, 794, 2749, 7801]</td>\n",
       "      <td>19</td>\n",
       "      <td>[1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...</td>\n",
       "      <td>7</td>\n",
       "      <td>[47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                             coauthors  year  \\\n",
       "0           0            [16336, 1762, 4357, 12564]    19   \n",
       "1           1                        [21189, 14088]    19   \n",
       "2           2  [3625, 1198, 19889, 794, 2749, 7801]    19   \n",
       "\n",
       "                                            abstract  venue  \\\n",
       "0  [37, 1662, 3207, 10, 33, 2037, 1738, 1642, 155...    223   \n",
       "1  [1731, 2130, 3674, 1705, 1656, 3077, 1546, 367...    223   \n",
       "2  [1551, 1728, 3920, 1542, 1535, 1656, 1543, 153...      7   \n",
       "\n",
       "                                               title  \n",
       "0  [3207, 24, 1798, 1738, 37, 2375, 1568, 11, 53,...  \n",
       "1  [40, 1560, 1536, 1544, 1609, 1705, 1658, 1543,...  \n",
       "2  [47, 1574, 1729, 1641, 11, 37, 2533, 2015, 47,...  "
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "8534a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthorDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, istrain):\n",
    "        self.data = dataframe\n",
    "        self.x = dataframe[['year', 'venue', 'coauthors', 'abstract', 'title']]\n",
    "        self.istrain = istrain\n",
    "        if self.istrain == True:\n",
    "            self.y = self.data.prolific_authors\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        year = self.data.year[index]\n",
    "        venue = self.data.venue[index]\n",
    "        title = self.data.title[index]\n",
    "        \n",
    "        # word2vec on abstract\n",
    "        #abstractmodel = Word2Vec.load(\"abstract_word2vec.model\")\n",
    "        abstract = self.data.abstract[index]\n",
    "        #abstract_vector = abstractmodel.wv[abstract]\n",
    "        \n",
    "        # coauthors to one hot\n",
    "        coauthors = self.data.coauthors[index]\n",
    "        coauthor_list = [0] * (n_authors - n_prolific + 2) # 21147 elements with the last element for empty coauthors\n",
    "        if coauthors == []:\n",
    "            coauthor_list[-1] = 1\n",
    "        else:\n",
    "            for coauthor in coauthors:\n",
    "                coauthor_list[coauthor-n_prolific] = 1\n",
    "                \n",
    "        x_output = {\"title\": title, \"abstract\": abstract, \"year\": year, \"venue\": venue, \"coauthors\": coauthor_list}\n",
    "        \n",
    "        # target to one hot\n",
    "        if self.istrain == True:\n",
    "            prolific_list = [0] * n_prolific\n",
    "            if self.y[index] != -1:\n",
    "                for prolific in self.y[index]:\n",
    "                    prolific_list[prolific] = 1\n",
    "            y_output = prolific_list\n",
    "            return x_output, y_output\n",
    "        else:\n",
    "            return x_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "id": "74030042",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = AuthorDataset(train_df, istrain = True)\n",
    "testing_df = AuthorDataset(test_df, istrain = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "id": "0425b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    # for training set\n",
    "    if len(batch[0]) == 2:\n",
    "        output = {\"title\": [], \"abstract\": [], \"year\": [], \"venue\": [], \"coauthors\": [], \"target\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            x = data[0]\n",
    "            target = data[1]\n",
    "            \n",
    "            output['title'] += [torch.tensor(x['title'], dtype=torch.long)]\n",
    "            output['abstract'] += [torch.tensor(x['abstract'], dtype=torch.long)]\n",
    "            output['year'] += [x['year']]\n",
    "            output['venue'] += [x['venue']]\n",
    "            output['coauthors'] += [torch.tensor(x['coauthors'], dtype=torch.long)]\n",
    "            output['target'] += [target]\n",
    "            \n",
    "        output['year'] = torch.tensor(output['year'], dtype=torch.long)\n",
    "        output['venue'] = torch.tensor(output['venue'], dtype=torch.long)\n",
    "        output['target'] = torch.tensor(output['target'], dtype=torch.float)\n",
    "        return output\n",
    "    \n",
    "    # for testing set\n",
    "    else:\n",
    "        output = {\"title\": [], \"abstract\": [], \"year\": [], \"venue\": [], \"coauthors\": []}\n",
    "        \n",
    "        for data in batch:\n",
    "            output['title'] += [torch.tensor(data['title'], dtype=torch.long)]\n",
    "            output['abstract'] += [torch.tensor(data['abstract'], dtype=torch.long)]\n",
    "            output['year'] += [data['year']]\n",
    "            output['venue'] += [data['venue']]\n",
    "            output['coauthors'] += [torch.tensor(data['coauthors'], dtype=torch.long)]\n",
    "            \n",
    "        output['year'] = torch.tensor(output['year'], dtype=torch.long)\n",
    "        output['venue'] = torch.tensor(output['venue'], dtype=torch.long)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1388,
   "id": "b0a5e9fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset = training_df, batch_size = batch_size, shuffle=True, collate_fn = my_collate)\n",
    "test_dataloader = DataLoader(dataset = testing_df, batch_size = batch_size, shuffle=False, collate_fn = my_collate)\n",
    "dataiter = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1385,
   "id": "860c9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_dim, hidden_dim, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.weights = torch.FloatTensor(keywords)\n",
    "        self.embedding = nn.Embedding.from_pretrained(self.weights)\n",
    "        self.embedding.requires_grad = False\n",
    "        self.embedding = nn.Embedding(n_text+1, embed_dim)\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_size, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 100)\n",
    "        self.activation=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        #self.lstm = nn.LSTM(input_size, hidden_dim, num_layers, batch_first=True)\n",
    "        #self.fc = nn.Linear(hidden_dim, 100)\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, _input):\n",
    "        titles = _input['title']\n",
    "        word2vec_title_list = []\n",
    "        for curr_title in titles:\n",
    "            title_vec = self.embedding(curr_title)\n",
    "            word2vec_title_list.append(title_vec.mean(dim = 0))\n",
    "        embed_title = torch.stack(word2vec_title_list)\n",
    "        \n",
    "        #out = embed_title.reshape([embed_title.shape[0],1,embed_title.shape[1]])\n",
    "        \n",
    "        \n",
    "        #embed_abstract_list = []\n",
    "        #for curr_abstract in x['abstract']:\n",
    "        #    embed_abstract_list.append(curr_abstract.mean(dim = 0))\n",
    "        #embed_abstract = torch.stack(embed_abstract_list) # torch.Size([4, 100])\n",
    "        #print(pad_sequence(x['title']).size())\n",
    "        #print(pad_sequence(x['abstract']).size())\n",
    "        #out = pad_sequence(_input['abstract'], batch_first=True)\n",
    "        #print(out.size())\n",
    "        #out = torch.cat((pad_sequence(x['title']), pad_sequence(x['abstract'])), dim = 0)\n",
    "        #print(out)\n",
    "        \n",
    "        #h0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        #c0 = torch.zeros(self.num_layers, out.size(0), self.hidden_dim)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        #out, (hn, cn) = self.lstm(out, (h0, c0))  \n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #out = self.fc(out[:, -1, :]) \n",
    "        #out = self.sigmoid(out)\n",
    "        #return out\n",
    "        logits=self.linear1(embed_title)\n",
    "        logits=self.activation(logits)\n",
    "        logits=self.linear2(logits)\n",
    "        return torch.sigmoid(logits)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1386,
   "id": "05ebbf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4762, 0.4931, 0.4964,  ..., 0.5286, 0.4926, 0.5050],\n",
      "        [0.4749, 0.4929, 0.5263,  ..., 0.5328, 0.4996, 0.5165],\n",
      "        [0.4822, 0.4710, 0.5092,  ..., 0.5133, 0.5115, 0.5122],\n",
      "        ...,\n",
      "        [0.4887, 0.4891, 0.5316,  ..., 0.5226, 0.5045, 0.5177],\n",
      "        [0.4652, 0.4945, 0.5133,  ..., 0.4973, 0.4881, 0.5011],\n",
      "        [0.4824, 0.4771, 0.5178,  ..., 0.5319, 0.4966, 0.5232]],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 1386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LSTM(64, 64, 128, 1)\n",
    "print(clf(dataiter))\n",
    "predictions = np.where(clf(dataiter).detach().numpy()>=0.5, 1, 0)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1387,
   "id": "50b1fb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 100, loss = 0.0313, training f1 score = 0.7391\n",
      "epoch 2 / 100, loss = 0.0226, training f1 score = 0.6957\n",
      "epoch 3 / 100, loss = 0.0249, training f1 score = 0.7826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/352945707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_total_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m#batch = batch.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/2852758823.py\u001b[0m in \u001b[0;36mmy_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'venue'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'venue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coauthors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coauthors'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(clf.parameters(),lr=0.1)\n",
    "\n",
    "# training loop\n",
    "n_total_steps = len(train_dataloader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        #batch = batch.to(device)\n",
    "\n",
    "        # forward\n",
    "        #print(batch)\n",
    "        outputs = clf(batch)\n",
    "        \n",
    "        loss = criterion(outputs, batch['target'])\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>=0.5, 1, 0)\n",
    "        #print(outputs.detach().numpy())\n",
    "        #break\n",
    "        f1_acc = f1_score(batch['target'].detach().numpy(), predictions, average=\"samples\", zero_division=1)\n",
    "\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #if (i + 1) % 1000 == 0:\n",
    "    print(f'epoch {epoch + 1} / {num_epochs}, loss = {loss.item():.4f}, training f1 score = {f1_acc:.4f}')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1378,
   "id": "1a579e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        outputs = clf(batch)\n",
    "        \n",
    "        predictions = np.where(outputs.detach().numpy()>0.5, 1, 0)\n",
    "        test_preds.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1379,
   "id": "de78fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 1379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[20][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1370,
   "id": "6dee4881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(lst, num):\n",
    "    result = []\n",
    "    for i, x in enumerate(lst):\n",
    "        if x==num:\n",
    "            result.append(i)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "id": "f65af5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3h/x2xrdjwn22bbdw5d98hd13w80000gn/T/ipykernel_56714/26654980.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mfinal_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 20"
     ]
    }
   ],
   "source": [
    "NN_result = test_df[['identifier']]\n",
    "NN_result.loc[:,'Predict'] = ''\n",
    "final_result = []\n",
    "for i in range(len(test_preds)):\n",
    "    for j in range(batch_size):\n",
    "        final_result.append(test_preds[i][j])\n",
    "print(len(final_result))\n",
    "for i in range(len(final_result)):\n",
    "    result = final_result[i]\n",
    "    if len(find(list(result), 1)) == 0:\n",
    "        NN_result.loc[i,'Predict'] = -1\n",
    "    else:\n",
    "        NN_result.loc[i,'Predict'] = ' '.join(str(e) for e in find(list(result), 1))\n",
    "        \n",
    "NN_result = NN_result.rename(columns={'identifier':'ID'})\n",
    "NN_result.to_csv('./NN_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "318970df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>Predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier Predict\n",
       "0             0        \n",
       "1             1        \n",
       "2             2        \n",
       "3             3        \n",
       "4             4        \n",
       "..          ...     ...\n",
       "795         795        \n",
       "796         796        \n",
       "797         797        \n",
       "798         798        \n",
       "799         799        \n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d34e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
